<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>HelloWorld</title>
    <url>/2023/02/28/HelloWorld/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>为什么要建立我的博客</p>
<ul>
<li>好记性不如烂笔头，<code>记录一些学到的技术</code></li>
<li><code>分享一些有趣的事</code></li>
<li>……</li>
</ul>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>一道ctf小题</title>
    <url>/2023/03/05/ctf-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>直接上源码：</p>
<div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="title function_ invoke__">highlight_file</span>(<span class="keyword">__FILE__</span>);</span><br><span class="line"><span class="title function_ invoke__">error_reporting</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="variable">$num</span> = <span class="variable">$_GET</span>[<span class="string">&#x27;num&#x27;</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="title function_ invoke__">preg_match</span>(<span class="string">&quot;/\&#x27;|\&quot;|\`| |&lt;|&gt;|?|\^|%|\$/&quot;</span>, <span class="variable">$num</span>)) &#123;</span><br><span class="line">           <span class="keyword">die</span>(<span class="string">&quot;nononno&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">eval</span>(<span class="string">&quot;return $&#123;num&#125; != 2;&quot;</span>) &amp;&amp; <span class="variable">$num</span> == <span class="number">0</span> &amp;&amp; <span class="title function_ invoke__">is_numeric</span>(<span class="variable">$num</span>) != <span class="literal">true</span>) &#123;</span><br><span class="line"> <span class="title function_ invoke__">system</span>(<span class="string">&#x27;cat flag.php&#x27;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"> <span class="keyword">echo</span> <span class="string">&#x27;2&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>分析：我们需要同时满足if表达式中的三个条件</p>
<div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">eval</span>(<span class="string">&quot;return $&#123;num&#125; != 2;&quot;</span>) &amp;&amp; <span class="variable">$num</span> == <span class="number">0</span> &amp;&amp; <span class="title function_ invoke__">is_numeric</span>(<span class="variable">$num</span>) != <span class="literal">true</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>第二个条件：要求get到的num弱等于0</p>
<ul>
<li><p>弱等于比较时，会先将字符串转换为数字，其转换方式就是截取开头的数字，不过还有两种特殊情况如下：</p>
<ul>
<li><p>如果没有数字，即就是一个纯字符串的话，转化为0</p>
</li>
<li><p>如果这个字符串恰好是一个科学技术法的表达式，会将此字符串按科学技术法转换为数字</p>
</li>
</ul>
</li>
<li><p>示例代码如下：</p>
</li>
</ul>
  <div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;admin&quot;</span>==<span class="number">0</span>);  <span class="comment">//true</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;1admin&quot;</span>==<span class="number">1</span>); <span class="comment">//true</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;2admin&quot;</span>==<span class="number">2</span>); <span class="comment">//true</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;ad1min&quot;</span>==<span class="number">1</span>); <span class="comment">//false</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;admin1&quot;</span>==<span class="number">1</span>); <span class="comment">//false</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="string">&quot;admin1&quot;</span>==<span class="number">0</span>); <span class="comment">//true</span></span><br><span class="line"><span class="title function_ invoke__">var_dump</span>(<span class="number">0e1234</span> == <span class="number">0e56789</span>); <span class="comment">//true </span></span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>第三个条件：要求get到的num不是数字类型</p>
<ul>
<li>这个很好说，只要不是纯数字就可以了</li>
</ul>
</li>
<li><p>第一个条件：让<code>$&#123;num&#125;!=2</code>返回1</p>
<ul>
<li><p>背景知识：</p>
<ul>
<li><p>eval()的返回值一般是<code>NULL</code>，除非执行的表达式是<code>return</code>，这种情况下，eval()的返回值就是return的值</p>
</li>
<li><p>php中的运算符优先级（跟Cpp基本一样哈）中比较运算的优先级大于双目位运算</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>根据条件3，我们输入的一定不是一个纯数字，所以要满足第一个条件的话，我们就必须考虑如php里面运算符的优先级和结合性，以便于能够成功输出</p>
<ul>
<li><p>方法一：<code>num=0|1</code></p>
</li>
<li><p>方法二：<code>num=0^0</code></p>
</li>
</ul>
<p>…知道了思路，方案肯定是有非常多的，在此就不列举了</p>
]]></content>
      <categories>
        <category>ctf</category>
        <category>web</category>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>3rd模块</title>
    <url>/2023/02/28/module_3rd/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>该模块用于保存本项目用到的两个第三方库的源码：</p>
<ol>
<li>fmt</li>
<li>nlohmann json</li>
</ol>
<p>在编译本项目时，除了编译与自瞄相关的代码，还会编译这两个第三方库，并将三者链接。</p>
<h2 id="fmt库简介"><a href="#fmt库简介" class="headerlink" title="fmt库简介"></a>fmt库简介</h2><p>fmt库为c++提供了一种类似python的输出格式化方法，比cout与printf更加的方便与安全。</p>
<p>具体用法详见<code>3rd/fmt</code>中的<a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/3rd/fmt/README.rst" >readme文件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>本项目使用这个库来实现logger模块。</p>
<h2 id="nlohmann-json库简介"><a href="#nlohmann-json库简介" class="headerlink" title="nlohmann json库简介"></a>nlohmann json库简介</h2><p>nlohmann json库为c++提供了读取json文件的功能，现有的c++ json库很多，nlohmann只是一种，不过它的速度跟易用性都是比较优秀的。</p>
<p>具体用法详见<code>3rd/json</code>中的<a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/3rd/json/README.md" >readme文件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>本项目将程序运行时的各种参数保存在<a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/assets/params.json" >json文件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>中，并使用这个库来读取json文件。</p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>assets模块</title>
    <url>/2023/02/28/module_assets/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>该模块用于保存一些与程序无关的文件。</p>
<ul>
<li>model_(bin|aug).onnx<br>  训练好的装甲板分类器</li>
<li>noclass.onnx<br>  训练好的目标检测器</li>
<li>test.onnx<br>  最早的目标检测器，已弃用</li>
<li>params.json<br>  程序运行时的参数配置文件</li>
<li>test-light.png<br>  一张没啥用的测试图片</li>
</ul>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>一道ctf小题（2）</title>
    <url>/2023/03/25/ctf-2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>直接上源码：</p>
<div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="title function_ invoke__">show_source</span>(<span class="keyword">__FILE__</span>);</span><br><span class="line"><span class="variable">$username</span>  = <span class="string">&quot;this_is_secret&quot;</span>; </span><br><span class="line"><span class="variable">$password</span>  = <span class="string">&quot;this_is_not_known_to_you&quot;</span>; </span><br><span class="line"><span class="keyword">include</span>(<span class="string">&quot;flag.php&quot;</span>);<span class="comment">//here I changed those two </span></span><br><span class="line"><span class="variable">$info</span> = <span class="keyword">isset</span>(<span class="variable">$_GET</span>[<span class="string">&#x27;info&#x27;</span>])? <span class="variable">$_GET</span>[<span class="string">&#x27;info&#x27;</span>]: <span class="string">&quot;&quot;</span> ;</span><br><span class="line"><span class="variable">$data_unserialize</span> = <span class="title function_ invoke__">unserialize</span>(<span class="variable">$info</span>);</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$data_unserialize</span>[<span class="string">&#x27;username&#x27;</span>]==<span class="variable">$username</span>&amp;&amp;<span class="variable">$data_unserialize</span>[<span class="string">&#x27;password&#x27;</span>]==<span class="variable">$password</span>)&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="variable">$flag</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;username or password error!&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></div>

<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h3><ul>
<li>serialize()函数用于序列化对象或数组，并返回一个字符串。</li>
<li>函数序列化对象后，可以很方便的将它传递给其他需要它的地方，且其类型和结构不会改变。</li>
<li>例子： <div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="variable">$a</span> = [</span><br><span class="line"><span class="string">&#x27;username&#x27;</span> =&gt; <span class="literal">true</span>,</span><br><span class="line"><span class="string">&#x27;password&#x27;</span> =&gt; <span class="literal">true</span></span><br><span class="line">];</span><br><span class="line"><span class="variable">$info</span> = <span class="title function_ invoke__">serialize</span>(<span class="variable">$a</span>);</span><br><span class="line"><span class="keyword">echo</span> <span class="variable">$info</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"><span class="comment"># a:2:&#123;s:8:&quot;username&quot;;b:1;s:8:&quot;password&quot;;b:1;&#125;</span></span><br></pre></td></tr></table></figure></div></li>
<li>unserialize()函数就是将序列化后的字符串反序列化成数组的过程</li>
</ul>
<h3 id="弱比较"><a href="#弱比较" class="headerlink" title="弱比较"></a>弱比较</h3><ul>
<li>这里要知道一个关于弱比较的特性：布尔类型True与非零非NULL变量比较都会是True。</li>
</ul>
<h2 id="题目解决"><a href="#题目解决" class="headerlink" title="题目解决"></a>题目解决</h2><ul>
<li><p>这个题有个非常坑的地方，你以为**include(“flag.php”);**只是将flag变量包含进来吗？</p>
</li>
<li><p>tnnd，这个文件里面把<strong>username</strong>和<strong>password</strong>都给改了！！！</p>
</li>
<li><p>所以呢，不能直接对原来那俩的值进行序列化，但是我们可以直接利用上面介绍的弱比较的特性</p>
</li>
<li><p>exp:</p>
  <div class="highlight-container" data-rel="Php"><figure class="iseeu highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="variable">$a</span> = [</span><br><span class="line"><span class="string">&#x27;username&#x27;</span> =&gt; <span class="literal">true</span>,</span><br><span class="line"><span class="string">&#x27;password&#x27;</span> =&gt; <span class="literal">true</span></span><br><span class="line">];</span><br><span class="line"><span class="variable">$info</span> = <span class="title function_ invoke__">serialize</span>(<span class="variable">$a</span>);</span><br><span class="line"><span class="keyword">echo</span> <span class="variable">$info</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></div></li>
<li><p>可以直接在<a class="link"   href="https://www.w3cschool.cn/tryrun/runcode?lang=php" >php在线 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>这里进行php在线编辑</p>
</li>
<li><p>得到的结果：a:2:{s:8:”username”;b:1;s:8:”password”;b:1;}</p>
</li>
<li><p>pyload:</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://43.142.108.3:28005/?info=a:2:&#123;s:8:%22username%22;b:1;s:8:%22password%22;b:1;&#125;</span><br></pre></td></tr></table></figure></div></li>
</ul>
]]></content>
      <categories>
        <category>ctf</category>
        <category>web</category>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>detector模块</title>
    <url>/2023/02/28/module_detector/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>该模块实现了目标检测分类器的加载以及前向传播过程，并且提供了两种实现方式：</p>
<ul>
<li>cv::dnn模块</li>
<li>nvidia推理框架TensorRT</li>
</ul>
<p>其中cv::dnn版本仅依赖OpenCV，但是前向传播的速度慢，因此用于在本机进行调试；TensorRT安装繁琐，但可以加速前向传播的计算速度，因此在minipc上使用。</p>
<p>两种版本可以通过宏定义切换。</p>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="cuda"><a href="#cuda" class="headerlink" title="cuda"></a>cuda</h3><p>cuda可以看作是第三方库，可以用于控制nvidia显卡。</p>
<p>在使用cuda时，我们会把内存分成两种，一种是cpu内存，一种是gpu内存（显存），cuda可以完成：</p>
<ul>
<li>申请、释放gpu内存：cudaMalloc，cudaFree</li>
<li>在cpu内存与gpu内存之间拷贝数据；cudaMemcpy</li>
<li>让gpu执行核函数进行计算：有兴趣自行学习。</li>
</ul>
<p>一个典型的cuda程序的流程：</p>
<ol>
<li>在cpu上把数据准备好</li>
<li>把数据从cpu拷贝到gpu</li>
<li>调用核函数进行计算</li>
<li>把计算结果拷贝回cpu</li>
</ol>
<h3 id="TensorRT"><a href="#TensorRT" class="headerlink" title="TensorRT"></a>TensorRT</h3><p>nvidia专门为深度学习编写的神经网络推理框架，可以优化网络的前向传播速度。它首先会读取.onnx里的网络，然后对网络的计算图进行优化，优化后的计算图我们可以保存下来，变成.engine文件。</p>
<p>在使用时，我们只需要负责数据的拷贝，前向传播计算由TensorRT来完成。</p>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="common-h"><a href="#common-h" class="headerlink" title="common.h"></a>common.h</h3><p>没什么用，想删但是懒得删。</p>
<h3 id="logging-h"><a href="#logging-h" class="headerlink" title="logging.h"></a>logging.h</h3><p>nvidia提供的，与TensorRT相关的头文件，不用看，但是必须要有。</p>
<h3 id="utils-h"><a href="#utils-h" class="headerlink" title="utils.h"></a>utils.h</h3><p>提供了一些detector的辅助函数，比如说解析网络输出的结果，nms等。不讲。</p>
<h3 id="dnn-h"><a href="#dnn-h" class="headerlink" title="dnn.h"></a>dnn.h</h3><p>让大家写过，不讲。</p>
<h3 id="trt-h-amp-trt-cc"><a href="#trt-h-amp-trt-cc" class="headerlink" title="trt.h &amp; trt.cc"></a>trt.h &amp; trt.cc</h3><p>使用TensorRT完成前向传播。TRT类各个成员函数的功能如下：</p>
<h4 id="load-from-onnx-…"><a href="#load-from-onnx-…" class="headerlink" title="load_from_onnx(…)"></a>load_from_onnx(…)</h4><p>加载onnx文件并进行计算图的优化，优化这一步很耗时，大概10~20min。</p>
<h4 id="save-engine-…"><a href="#save-engine-…" class="headerlink" title="save_engine(…)"></a>save_engine(…)</h4><p>将优化后的计算图保存到磁盘中，变成.engine文件。</p>
<h4 id="load-from-cache-…"><a href="#load-from-cache-…" class="headerlink" title="load_from_cache(…)"></a>load_from_cache(…)</h4><p>直接加载.engine文件。</p>
<h4 id="bind"><a href="#bind" class="headerlink" title="bind()"></a>bind()</h4><p>根据计算图的信息（输出tensor的个数，大小）来分配cpu内存与gpu内存。</p>
<h4 id="detect"><a href="#detect" class="headerlink" title="detect()"></a>detect()</h4><p>看注释。</p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>logger模块</title>
    <url>/2023/02/28/module_logger/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>该模块基于c++第三方库<code>fmt</code>实现了一个logger用于保存程序运行时的一些信息。支持以下功能：</p>
<ul>
<li>提供3种级别的log：<ul>
<li><strong>MSG</strong>：输出一些基本的信息，例如当前目标的数量，解算出的世界坐标</li>
<li><strong>WARINING</strong>：输出一些警告信息，例如串口收到的数据存在异常</li>
<li><strong>ERROR</strong>：输出一些错误信息，例如相机读取失败</li>
</ul>
</li>
<li>能够在log信息输出到文件 or 终端。</li>
<li>能够保存图片到本地（未实际使用）</li>
</ul>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="关于logger"><a href="#关于logger" class="headerlink" title="关于logger"></a>关于logger</h3><p>正经的项目都会针对自己的需求设计一个logger用来保存程序运行时的信息，可以用于程序数据分析或者debug。</p>
<p>简单来说logger可以看作是一个稍微复杂的printf。它会包含一个前端，用于将你要输出的信息进行格式化，比如：</p>
<ul>
<li>信息产生的位置（文件名、函数名、行号、线程id）</li>
<li>信息的类型（error, msg, …）</li>
</ul>
<p>请查看知乎上的<a class="link"   href="https://www.zhihu.com/question/293863155?sort=created" >关于c++ logger的讨论 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，这个问题下有一些人回答了logger的作用，怎么合理的设计一个logger等问题。</p>
<p><a href="assets/log.h">log.h</a>文件中给了一个logger的示例，使用c&#x2F;c++的宏定义 &amp; printf实现一个最简单的logger。先试着用一下这个log.h。</p>
<h3 id="关于c-单例模式"><a href="#关于c-单例模式" class="headerlink" title="关于c++单例模式"></a>关于c++单例模式</h3><p>单例模式的意思就是让某一个类只能实例化唯一的一个对象，比如说这里的logger，一个程序只会有一个logger，所以我们会把logger这个类设计成单例，程序运行期间所有的信息都会交给这个唯一的logger进行保存。</p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/62014096" >单例模式的实现方式 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，只需要查看其中的实现四即可。</p>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="log-h"><a href="#log-h" class="headerlink" title="log.h"></a>log.h</h3><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/logger/log.h" >代码地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>该头文件用宏定义提供了一些logger相关的api，我们在程序中可以使用这些api来调用logger。主要使用以下api：</p>
<ul>
<li><p>ERROR(format, …)：打印错误信息，会显示为红色，e.g.</p>
  <div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">ERROR(&quot;parameter &#x27;a&#x27; should greater than zero, received &#123;&#125;&quot;, a)</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>MSG(format, …)：打印普通信息，会显示为蓝色</p>
</li>
<li><p>TRACE(code, tag)：打印一段程序的运行时间，以ms为单位，tag用来标注这段程序的含义，e.g.</p>
  <div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 逗号前面是代码段，逗号后面是tag</span><br><span class="line">TRACE(</span><br><span class="line">    for (int i = 0; i &lt; 1000; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        // do something ...</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;loop&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>…</p>
</li>
</ul>
<h3 id="log-formatter-h-amp-log-type-h"><a href="#log-formatter-h-amp-log-type-h" class="headerlink" title="log_formatter.h &amp; log_type.h"></a>log_formatter.h &amp; log_type.h</h3><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/logger/log_formatter.h" >代码地址(log_formatter.h) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/logger/log_type.h" >代码地址(log_type.h) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>该头文件实现了一个LogFormatter类，提供一个format函数对程序信息进行格式化，很简单，不讲。</p>
<h3 id="logger-h"><a href="#logger-h" class="headerlink" title="logger.h"></a>logger.h</h3><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/logger/logger.h" >代码地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>使用RMLogger类实现了logger。关键代码如下：</p>
<ul>
<li><code>get_logger()</code><br>  获取唯一的logger对象的指针，使用的是最简单的单例模式。</li>
<li><code>_sync_print()</code><br>  实际上就是加了互斥锁的fmt::print，防止多个线程同时使用logger打印时输出结果混乱。</li>
<li><code>_sync_flush()</code><br>  与_sync_print()类似，只不过是把信息输出到文件。</li>
<li><code>save_log()</code><br>  保存日志信息，会在log.h中被调用。使用了可变参数模板用于接收任意多个参数，自行百度学习。</li>
</ul>
<p>还有一些跟fmt库相关的代码，让fmt库能够格式化自定义的类型，e.g.</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">cv::Point3f p = &#123;1., 2., 3.&#125;;</span><br><span class="line">fmt::print(&quot;velocity = &#123;&#125;\n&quot;, p);</span><br></pre></td></tr></table></figure></div>

<p>如果不添加以下代码的话：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">// format 3rd types</span><br><span class="line">template&lt;&gt; struct fmt::formatter&lt;cv::Point3f&gt; &#123;</span><br><span class="line">    char presentation = &#x27;f&#x27;;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></div>

<p>fmt::print是会报错的，因为它不知道该怎么格式化cv::Point3f。如何编写这个自定义格式化代码：<a class="link"   href="https://zhuanlan.zhihu.com/p/601744791" >https://zhuanlan.zhihu.com/p/601744791 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>armor模块</title>
    <url>/2023/02/28/module_armor/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul>
<li>对应代码: 为 <code>include/armor</code> 和 <code>src/armor</code> 文件夹</li>
<li>功能：识别装甲板<ul>
<li>输入当前帧的图片</li>
<li>输出识别到的图片中装甲板的位置</li>
</ul>
</li>
</ul>
<h2 id="大致思路"><a href="#大致思路" class="headerlink" title="大致思路"></a>大致思路</h2><ol>
<li>使用 <code>yolofastedv2</code> 检测装甲板(但是深度学习方法检测到的装甲板边缘位置不稳定)</li>
<li>然后在深度学习得到的装甲板的 ROI 内使用传统算法检测<ol>
<li>在 ROI 中找到灯条</li>
<li>匹配灯条得到装甲板</li>
</ol>
</li>
</ol>
<h2 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h2><table>
<thead>
<tr>
<th>文件 <code>include/armor</code> 下</th>
<th>类 &#x2F; 结构体</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td><code>light.h</code></td>
<td><code>Light</code></td>
<td>灯条数据结构</td>
</tr>
<tr>
<td><code>armor.h</code></td>
<td><code>Armor</code></td>
<td>装甲板数据结构</td>
</tr>
<tr>
<td><code>finder.h</code></td>
<td><code>ArmorFinder</code></td>
<td>整个识别装甲板的过程</td>
</tr>
<tr>
<td><code>detector</code></td>
<td></td>
<td>深度学习识别器</td>
</tr>
<tr>
<td><code>classifier</code></td>
<td></td>
<td>分类器</td>
</tr>
</tbody></table>
<h3 id="分类器部分"><a href="#分类器部分" class="headerlink" title="分类器部分"></a>分类器部分</h3><p>实现了两种分类器</p>
<ul>
<li><strong>神经网络方法</strong>: 我们最后采用的方法，和 <code>detector</code> 部分类似，都是使用 <code>torch</code> 训练，然后用 <code>c++</code> 调用神经网络进行分类</li>
<li>KNN方法: 很早写的，可能现在无法直接运行 (由于 <code>dataset.cc</code> 中文件路径有关)</li>
</ul>
<table>
<thead>
<tr>
<th>文件 <code>include/armor/classifier</code> 下</th>
<th>类 &#x2F; 结构体</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td><code>classifier.h</code></td>
<td><code>ArmorClassifier</code></td>
<td>分类器父类</td>
</tr>
<tr>
<td><code>mlp.h</code></td>
<td><code>MLP</code></td>
<td>多层感知机分类器(目前用的这个)</td>
</tr>
<tr>
<td><code>knn.h</code></td>
<td><code>KNN</code></td>
<td>KNN 分类器(没用选用)</td>
</tr>
<tr>
<td><code>kmeans.h</code></td>
<td><code>KMeans</code></td>
<td>KNN方法中的 KMeans聚类(KNN里用)</td>
</tr>
<tr>
<td><code>dataset.h</code></td>
<td><code>DataSet</code></td>
<td>KNN方法中用</td>
</tr>
</tbody></table>
<p><code>classifier.h</code> 中定义了分类器的两个接口，使得其他部分代码在使用分类器的时候，能选择不同的分类器</p>
<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>文件: <code>include/armor/light.h</code> 和 <code>include/armor/armor.h</code>，定义了灯条和装甲板的数据结构</p>
<p>每个可击打单位，身上都有一定数量的装甲板，只有当子弹以一定速度打在装甲板上才会掉血。而每个装甲板有两个灯条，由于在视野中，灯条很亮，所以我们使用灯条来识别装甲板。</p>
<h3 id="灯条-light-h"><a href="#灯条-light-h" class="headerlink" title="灯条 light.h"></a>灯条 light.h</h3><p>在文件 <code>include/armor/light.h</code> 中定义了灯条的数据结构 <code>Light</code> 结构体</p>
<p>成员属性</p>
<ul>
<li><code>color</code>: 颜色(红色或蓝色)</li>
<li><code>rect</code>: 使用 <code>opencv</code> 的 <code>RotatedRect</code> 来表示灯条的位置和方向</li>
<li>灯条面积和长度(用于过滤灯条)</li>
</ul>
<h3 id="装甲板-armor-h"><a href="#装甲板-armor-h" class="headerlink" title="装甲板 armor.h"></a>装甲板 armor.h</h3><p>在文件 <code>include/armor/armor.h</code> 中定义了装甲板的数据结构 <code>Armor</code> 结构体</p>
<p>成员属性</p>
<ul>
<li>表示装甲板位置的两种方法(对应 <code>src/predictor/trans.cc</code> 中 <code>/*图像坐标系下特征点坐标*/</code> 下面的两种计算 <code>img_points</code> 方法)<ul>
<li><code>rect</code>: 使用 <code>opencv</code> 的 <code>Rect</code> 来表示装甲板的位置</li>
<li><code>rect_point</code>: 使用四个 <code>Point2f</code> 来表示装甲板的四个顶点</li>
</ul>
</li>
<li>其他信息<ul>
<li><code>id</code>: 装甲板所在单位的类别(英雄 or 步兵等)</li>
<li><code>color</code>: 颜色(红色 or 蓝色)</li>
<li><code>is_big</code>: 装甲板尺寸有大小两种，用于后续 solve_pnp</li>
</ul>
</li>
</ul>
<h3 id="其他辅助函数"><a href="#其他辅助函数" class="headerlink" title="其他辅助函数"></a>其他辅助函数</h3><p>在这两个文件中，还有很多其他的辅助函数，功能注释里都有说明。</p>
<h2 id="finder-h"><a href="#finder-h" class="headerlink" title="finder.h"></a>finder.h</h2><p>在 <code>include/armor/finder.h</code> 中定义了 <code>ArmorFinder</code> 类，该类实现了整个识别装甲板的过程，该类的对外<strong>唯一</strong>接口为 <code>AutoAiming</code> 函数。</p>
<h3 id="AutoAiming"><a href="#AutoAiming" class="headerlink" title="AutoAiming"></a>AutoAiming</h3><p>该函数的输入为当前帧的图片，输出为识别到的 <code>Armor</code>。</p>
<p>大致流程如下：</p>
<ol>
<li>使用深度学习方法找到大致位置<ol>
<li>使用 <code>yolofastedv2</code> 检测装甲板，得到一堆装甲板</li>
<li>找到最接近图像中心的装甲板(即相对更接近当前弹道的)</li>
<li>计算该装甲板的位置，并扩大一定倍数得到 ROI</li>
</ol>
</li>
<li>使用传统算法找到装甲板<ol>
<li>调用 <code>ArmorFinder::FindLights</code> 函数，找到 ROI 内的灯条</li>
<li>调用 <code>ArmorFinder::MatchLights</code> 函数，匹配灯条得到装甲板</li>
<li>对每一个匹配到的装甲板(大概率只有一个)，分类其装甲板所在单位类型</li>
</ol>
</li>
<li>防抖(即防止不断目标切换)<ul>
<li>如果和上一帧的装甲板是一个，就用当前识别到的装甲板</li>
<li>如果不一样，就使用上一帧的装甲板</li>
<li>如果连续多次都不一样，说明原来目标已经丢失了，就使用当前识别到的装甲板</li>
</ul>
</li>
</ol>
<p>在以上流程中，使用到了两个该类中的成员函数 <code>FindLights</code> 和 <code>MatchLights</code>。</p>
<h3 id="FindLights"><a href="#FindLights" class="headerlink" title="FindLights"></a>FindLights</h3><ul>
<li>输入: 当前帧的图片</li>
<li>输出: 识别到的所有灯条</li>
</ul>
<p>大致流程：</p>
<ol>
<li>预处理<ol>
<li>通道提取(基于目标颜色)</li>
<li>二值化</li>
<li>腐蚀膨胀</li>
</ol>
</li>
<li><code>findContours</code> 找轮廓，这个函数是传统视觉算法的核心，在 <code>finder.cc</code> 里有很详细的参数说明</li>
<li>找到是灯条的轮廓，使用 <code>Light</code> 中的辅助函数</li>
</ol>
<h3 id="MatchLights"><a href="#MatchLights" class="headerlink" title="MatchLights"></a>MatchLights</h3><ul>
<li>输入<ul>
<li>当前帧图片</li>
<li>roi</li>
<li>灯条列表</li>
</ul>
</li>
<li>输出: 装甲板列表</li>
</ul>
<p>大致流程: 对于每一对灯条</p>
<ol>
<li>判断能否组成装甲板(根据 <code>Light</code> 中的辅助函数)</li>
<li>如果能成功匹配，计算 <code>armor</code> 的位置<ul>
<li>方法1: 矩形表示 <code>cv::Rect</code><ol>
<li>灯条 <code>RotatedRect</code> 旋转矩形 -&gt; <code>Rect</code> 矩形</li>
<li>计算得到装甲板的 <code>Rect</code></li>
</ol>
</li>
<li>方法2: 任意四边形表示 4个 <code>cv::Point2f</code><ol>
<li>首先区分这两个灯条的左右</li>
<li>计算两个灯条的角度，并转成弧度制，以及两个灯条的长度</li>
<li>根据三角函数，计算出装甲板的四个顶点</li>
</ol>
</li>
</ul>
</li>
</ol>
<p>PS:</p>
<ul>
<li>关于几何计算<ul>
<li>计算 <code>armor</code> 位置的算法，就是纯几何问题，只不过要用 <code>opencv</code> 实现</li>
<li><code>opencv</code> 不同的版本，数据结构上可能不同<ul>
<li>旋转矩形可能有些不同(weight or height, 角度等)</li>
<li>甚至 <code>c++</code> 和 <code>python</code> 中也有区别 (<code>Rect</code> 在 <code>c++</code> 中存的中心点坐标，在 <code>python</code> 中是左上角的点坐标)</li>
</ul>
</li>
<li>所以一切以实际效果为准来编写代码</li>
</ul>
</li>
</ul>
<h2 id="classifier"><a href="#classifier" class="headerlink" title="classifier"></a>classifier</h2><h3 id="mlp-h"><a href="#mlp-h" class="headerlink" title="mlp.h"></a>mlp.h</h3><p>和 <code>detector/dnn.h</code> 类似，也是使用 <code>opencv</code> 的 <code>dnn</code> 模块来读取训练好的神经网络，然后进行预测。</p>
<p>文件名解释: 一开始直接用的全连接神经网络mlp进行分类，所以就叫成mlp.h了，实际使用的是 LeNet，是卷积神经网络。</p>
<p><code>predict</code> 函数输入的是 <code>armor</code> 所在区域的子图，输出分类结果。</p>
<p>步骤大致如下：</p>
<ol>
<li>预处理(二值化)<ol>
<li>二值化</li>
<li>去除左右变界亮光<ul>
<li>对应到代码是 <code>// clear lignt</code> 那一行接下来的部分</li>
<li>做这部分的原因<ul>
<li>输入的子图区域，有时是[灯条 + 数字]，有时只有[数字]</li>
<li>为了去掉有时出现的灯条的影响，直接预处理去掉左右可能存在的灯条</li>
</ul>
</li>
</ul>
</li>
<li>resize 到和神经网络标准输入大小一致</li>
</ol>
</li>
<li>使用神经网络进行分类</li>
</ol>
<h3 id="knn-h-kmeans-h-dataset-h"><a href="#knn-h-kmeans-h-dataset-h" class="headerlink" title="knn.h, kmeans.h, dataset.h"></a>knn.h, kmeans.h, dataset.h</h3><p>这三个文件共同实现了一个 knn 分类器，理解了 knn 算法，就能看到这部分代码。</p>
<p>knn 分类方法最后并没有使用，直接用 MLP 的方法就行。</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p><a class="link"   href="https://gitee.com/cbxgss/learn-cmake" >cmake简单例子 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>中心投影！</title>
    <url>/2023/04/24/rm-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>由于工业相机所拍摄图片实际上是三维空间-&gt;二维成像平面的<strong>中心投影</strong>而不是平心投影，故原有的很多<strong>先验条件</strong>（灯条识别与灯条匹配）是不成立的。</p>
<p>以下为失效的先验条件：</p>
<ul>
<li>判断两个灯条的相对位置，源码如下：</li>
</ul>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*  该指标的含义为：</span></span><br><span class="line"><span class="comment"> * 	1. 先将两个灯条的中心点垂直映射到 两个灯条的平均方向上的直线上</span></span><br><span class="line"><span class="comment"> * 	2. 然后计算两个灯条的中心点在这条直线上的投影距离</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">float</span> <span class="title">Offset</span><span class="params">(<span class="type">const</span> Light&amp; x, <span class="type">const</span> Light&amp; y)</span> </span>&#123;</span><br><span class="line">	<span class="type">float</span> angle = <span class="built_in">Verticality</span>(x, y) * CV_PI / <span class="number">180.0</span>;</span><br><span class="line">	<span class="comment">/* 灯条中心偏移向量 */</span></span><br><span class="line">	<span class="type">float</span> dx = y.rect.center.x - x.rect.center.x;</span><br><span class="line">	<span class="type">float</span> dy = y.rect.center.y - x.rect.center.y;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">abs</span>(<span class="built_in">cos</span>(angle) * <span class="built_in">abs</span>(dx) - <span class="built_in">sin</span>(angle) * <span class="built_in">abs</span>(dy));</span><br><span class="line">	<span class="comment">// return abs(cos(angle) * dx - sin(angle) * dy);</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><strong>失效原因</strong>：虽然说在实际的三维立体世界中，上述条件是肯定有效的，但是，我们是在二维成像平面中去判断的，即使从三维空间-&gt;二维成像平面的过程是平行投影，这个条件也不成立，更何况是中心投影了！</p>
<p><strong>失效后果</strong>：本来这个先验条件的设置应该是为了过滤掉如下图所示的情况，实际情况可能也还好，但是这样的话，由于这个先验条件本来就是错误的，它并不能正确有效的反映出二维平面投影下装甲板的真实特征，所以有一些正确的灯条匹配会因为这个<strong>错误的先验条件</strong>而被过滤！！</p>
<p><img src="/images/IMG_3941.jpg" alt="Test"></p>
<p><strong>解决方案</strong>：</p>
<p>a) 直接使用类似上交的四点模型，进行纯深度学习识别，完全抛弃传统视觉，直接避开这个问题？</p>
<p>b) 读君神的代码（因为现在已知君神的代码是使用的纯传统视觉），或者说直接询问，看看他是这么解决的！</p>
<p>c) 继续使用现有方案，但是要将阈值调到一个合适的值（能过滤掉大部分假装甲板，又不至于将大量的真装甲板过滤掉！）</p>
<p>d) 训练一个良好的神经网络，其输出能够大致保证框且仅框出一个装甲板，这样的话我们发现就不需要保留这个先验条件了（因为这个先验条件所解决的问题已经不会出现了，所以这个先验条件也可以随之消失了！！）</p>
]]></content>
      <categories>
        <category>rm</category>
        <category>armor_detect</category>
      </categories>
      <tags>
        <tag>rm</tag>
      </tags>
  </entry>
  <entry>
    <title>robot_io模块</title>
    <url>/2023/02/28/module_robot_io/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>自瞄程序需要在运行时读取相机的画面以及从串口读取机器人自身的信息，在目标定位完成后还要向串口写入机器人控制信息。</p>
<p>该模块对相机跟串口这两个硬件进行了封装，提供简单的api来实现以下功能：</p>
<ul>
<li>视频文件&#x2F;相机设备的读取</li>
<li>串口信息的读取&#x2F;写入</li>
</ul>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="串口"><a href="#串口" class="headerlink" title="串口"></a>串口</h3><p>串口类似于电话线，一端连着运行着自瞄程序的minipc，另一端连着电控组的更mini的pc，用于两端通信。</p>
<p>通信是以字节为单位进行的，两端要提前制定好通信协议，比如说：</p>
<ul>
<li>一次发送多少个字节</li>
<li>每一段的含义是什么</li>
</ul>
<p>举个例子，一次发送4个字节，前4个字节表示整数坐标x，后4个字节表示整数坐标y，那么每次发送数据就相当于发送下面这个结构体：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct Data &#123;</span><br><span class="line">    int x;</span><br><span class="line">    int y;</span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure></div>

<p>其中<code>__attribute__((packed))</code>是必须的，这是为了防止编译器在编译这个结构体时进行<a class="link"   href="https://blog.csdn.net/xxtzzxx/article/details/122439862" >内存对齐 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，造成该结构体包含额外的字节。</p>
<p>当串口连上电脑后，linux会检测到它，linux的一个设计理念就是”一切皆文件”，所以串口会被当作一个文件来对待，这个文件实际上是一块内存区域，称为串口缓冲区，并且会对应一个文件描述符。这样我们就可以使用fread()函数或者fwrite()函数来读写这个缓冲区（串口）了。</p>
<p>在自瞄程序这边，我们会写一个串口类来管理串口的读写。</p>
<h3 id="相机"><a href="#相机" class="headerlink" title="相机"></a>相机</h3><p>相机是一个硬件，只要是硬件就必须通过对应的驱动程序来控制它或者访问它，我们的机器人现在使用的相机是<a class="link"   href="https://www.daheng-imaging.com/" >大恒工业相机 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，它的官网上就提供了<a class="link"   href="https://www.daheng-imaging.com/downloads/softwares/" >SDK <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。之前用过迈德威视（mindvision）。</p>
<p>SDK中包括了相机驱动以及一些厂商提前写好的程序，比如说预览相机画面的程序。</p>
<p>我们主要使用的是它提供的驱动，驱动可以看作是专属于这个相机的第三方库，它包含一个头文件，里面一些函数可以用来在程序中控制相机，比如说<code>include/robot_io/video/da_heng/GxIAPI.h</code>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">\brief      Open the device by a specific unique identification, such as: SN, IP, MAC, Index etc.</span><br><span class="line">\attention  It is recommended that you call the GxUpdateDeviceList() interface to make an enumeration before calling</span><br><span class="line">            the function. To ensure that device list within the library is consistent with the current device.</span><br><span class="line">...</span><br><span class="line">GX_API GXOpenDevice (GX_OPEN_PARAM *pOpenParam, GX_DEV_HANDLE *phDevice);</span><br></pre></td></tr></table></figure></div>

<p>我们想要使用这个相机，就得先大概对这些api有了解。</p>
<p>只有头文件是运行不了的，还得有对应的函数定义。这个第三方库与fmt&#x2F;json不同，它<strong>不提供源码，只提供提前编译好的动态链接库</strong>。所以我们看不到它的函数具体实现方式。</p>
<p>动态链接库可以保存在项目源代码里（迈德威视），比如说<code>include/robot_io/video/mindvision/libMVSDK-pc.so</code>；也可以直接保存到系统库里（大恒），然后在编译的时候加上编译选项<code>-lgxiapi</code>让编译器自动去链接。</p>
<p>总结一下，程序访问相机的步骤为：</p>
<ol>
<li>买一个相机，下载厂商提供的SDK工具包。</li>
<li>安装工具包，将工具包中的头文件复制到自己的项目中。</li>
<li>看懂头文件中的api，然后调用这些函数。</li>
<li>编译程序时，额外去链接头文件对应的动态链接库。</li>
</ol>
<p>为了方便的使用相机，我们会写一个相机类来专门负责相机的操作。</p>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="串口-1"><a href="#串口-1" class="headerlink" title="串口"></a>串口</h3><p>所有跟相机有关的代码都在<code>include/robot_io/serial</code>中，对应的实现是<code>src/robot_io/serial</code>。接下来逐一解析各个代码文件的作用。</p>
<h4 id="crc-h"><a href="#crc-h" class="headerlink" title="crc.h"></a>crc.h</h4><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/robot_io/serial/crc.h" >代码地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>这个文件实现了数据的crc校验。crc校验就是确保一段二进制数据在传输过程中没有发生变化，它的原理就是根据二进制数据序列的值计算出一个crc校验值。</p>
<p>如果一段数据在传输前后计算出的校验值不变的话，就代表数据没有发生变化。</p>
<p>crc校验的具体细节不用管，我们只需要用<code>append_crc(8|16)_check_sum()</code>这两个函数计算crc校验值就ok。</p>
<h4 id="serial-h"><a href="#serial-h" class="headerlink" title="serial.h"></a>serial.h</h4><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/robot_io/serial/serial.h" >代码地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>首先有一些结构体：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct FrameHeader</span><br><span class="line">&#123;</span><br><span class="line">	uint8_t  	sof;			// SOF</span><br><span class="line">	uint8_t  	crc8;			// CRC8У����</span><br><span class="line">&#125;  __attribute__((packed));</span><br><span class="line">...</span><br><span class="line">struct SendData &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure></div>

<p>这些结构体就描述了与电控端商定好的通讯协议，比如说我们发送给电控端的数据是<code>SendData</code>，从电控端读取的数据是<code>ReceivedData</code>。各字段的含义看代码注释。</p>
<p>然后是两个跟串口有关的类，以及两个值得提一下的函数。</p>
<h5 id="Serial类"><a href="#Serial类" class="headerlink" title="Serial类"></a><code>Serial</code>类</h5><p><code>Serial</code>类用来管理串口的读取与写入，但没有规定数据的格式（网上抄的）。各个成员函数的作用如下：</p>
<ul>
<li>get_uart_dev_name()<br>串口被视为一个文件，该函数用于获取串口的文件名。</li>
<li>init_port(…)<br>初始化串口。</li>
<li>(read|write)_data(…)<br>读取或写入数据。</li>
</ul>
<p><strong>这个类不用完全看懂，会用就行。</strong></p>
<h5 id="SerialManager类"><a href="#SerialManager类" class="headerlink" title="SerialManager类"></a><code>SerialManager</code>类</h5><p><code>SerialManager</code>类是基于<code>Serial</code>类编写的，将数据固定成我们跟电控端约定好的数据格式。它包含两个public的成员变量<code>received_data_</code>跟<code>send_data_</code>，用于存储当前从串口中读取或将要写入的数据。</p>
<h5 id="uart-receive"><a href="#uart-receive" class="headerlink" title="uart_receive(...)"></a><code>uart_receive(...)</code></h5><p>这个函数用于从串口中读取数据（InputData）。在main函数中，我们会单独开启一个线程，这个线程会执行这个函数，从而实时的读取串口数据。</p>
<h5 id="TryToInitializeSerialBuffer"><a href="#TryToInitializeSerialBuffer" class="headerlink" title="TryToInitializeSerialBuffer(...)"></a><code>TryToInitializeSerialBuffer(...)</code></h5><p>程序运行过程中串口可能会由于usb口松动等原因发送错误的数据，此时我们会重新初始化串口。这个函数是为了在重新初始化串口时清除串口缓冲区中残留的无用数据，使得我们读取的第一个字节一定正好是输入数据的第一个字节。</p>
<h3 id="相机-1"><a href="#相机-1" class="headerlink" title="相机"></a>相机</h3><p>所有跟相机有关的代码都在<code>include/robot_io/video</code>中，对应的实现是<code>src/robot_io/video</code>。接下来逐一解析各个代码文件的作用。</p>
<h4 id="video-interface-h"><a href="#video-interface-h" class="headerlink" title="video_interface.h"></a>video_interface.h</h4><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/robot_io/video/video_interface.h" >代码地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h5 id="Matstamp类"><a href="#Matstamp类" class="headerlink" title="Matstamp类"></a><code>Matstamp</code>类</h5><p>这个类用来存储某一帧自瞄算法的输入信息，包括时间(ms)，相机图像，串口关键数据（yaw, pitch）。</p>
<h5 id="VideoInterface类"><a href="#VideoInterface类" class="headerlink" title="VideoInterface类"></a><code>VideoInterface</code>类</h5><p>我们的程序不仅可以读取相机，在测试时还可以读取视频。视频跟相机都可以看作是由一张张图像构成的视频流（video），都会提供一个<code>read()</code>函数用来从中读取一帧图像，因此我们在设计代码时使用了多态。</p>
<p>具体的，在<code>video_iterface.h</code>这个文件中我们定义了<code>VideoInterface</code>类，它相机类与视频类的父类，为相机或者视频定义了两个接口：</p>
<ul>
<li>Init：初始化视频流</li>
<li>Read：读取一帧图像</li>
</ul>
<p>不管是相机还是视频，都会继承这个VideoInterface，并实现上述两个成员函数。</p>
<p>在实际使用时，代码如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">VideoInterface* video_interface = new CameraWrapper(...);</span><br><span class="line">or</span><br><span class="line">VideoInterface* videp_interface = new VideoWrapper(...);</span><br></pre></td></tr></table></figure></div>

<p>也就是把子类指针转化为父类指针，后续代码就只需要使用video_interface的read接口即可，这样做的好处就是我们要改变视频流时，只需要改初始化，不需要修改后续的读取代码。</p>
<p>同时，如果后续需要添加新的相机的话，也只需要继承这个类就行，不用更改别的代码。</p>
<p>相机类的代码大部分都是参考的大恒SDK文档，而且已经能用了，等大家需要修改的时候再看文档也行。</p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>params模块</title>
    <url>/2023/02/28/module_params/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="模块总览"><a href="#模块总览" class="headerlink" title="模块总览"></a>模块总览</h2><p>该模块允许我们把自瞄算法的参数保存在配置文件（json）中，并在程序运行时把配置文件加载到内存中。</p>
<p>好处：每次修改算法参数后，不需要重新编译整个程序（耗时大概5min），所以能够减少程序编译耗时，提高代码调试速度。</p>
<p>一个例子：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">// json文件：</span><br><span class="line">// &#123;</span><br><span class="line">//     &quot;key1&quot;: 0.5,</span><br><span class="line">//     &quot;key2&quot;: &quot;string&quot;,</span><br><span class="line">//     &quot;key3&quot;: &#123;</span><br><span class="line">//         &quot;key1&quot;: [1, 2, 3]</span><br><span class="line">//     &#125;</span><br><span class="line">// &#125;</span><br><span class="line">// 代码：</span><br><span class="line">ParamsManager&amp; obj = *ParamsManager::GetInstance();</span><br><span class="line">obj.load(&quot;path/to/your/json/file&quot;);</span><br><span class="line"></span><br><span class="line">float x = obj[&quot;key1];</span><br><span class="line">std::string y = obj[&quot;key2];</span><br><span class="line">std::vector&lt;int&gt; z = obj[&quot;key3][&quot;key1];</span><br></pre></td></tr></table></figure></div>

<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="params-manager-h"><a href="#params-manager-h" class="headerlink" title="params_manager.h"></a>params_manager.h</h3><p><a class="link"   href="https://gitee.com/tju-rm-cv/tjurm-2022/blob/master/include/params/params_manager.h" >代码地址（头文件） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>使用ParamsManager类来读取（写入）配置文件，这个类也使用了单例模式。关键代码如下：</p>
<ul>
<li><code>nlohmann::json params_</code><br>  实际保存json文件的json对象。</li>
<li><code>load(const std::string&amp;)</code><br>  加载json文件。</li>
<li><code>dump(const std::string&amp;)</code><br>  将json对象保存成json文件。</li>
<li><code>nlohmann::json&amp; operator[](const std::string&amp;)</code><br>  提供[]操作符，输入一个字符串（key），返回一个json对象（value），由于json对象也支持[]操作符，所以用起来就跟python字典很像。</li>
</ul>
<p>nlohmann json这个库实际上做的事情是：</p>
<ol>
<li><p>将json文件里的各个值读取成nlohmann::json对象</p>
</li>
<li><p>当我们将json对象赋值给某一个变量时，会触发一个函数：</p>
 <div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">template&lt;typename T&gt;</span><br><span class="line">void from_json(nlohmann::json&amp; j, T&amp; p);</span><br></pre></td></tr></table></figure></div>

<p> 与该函数类似的还有一个to_json，该函数的作用是将json对象转化为对应的变量类型，对于内置类型，例如float, string, vector等，库本身已经实现好了对应的from_json&#x2F;to_json函数。</p>
<p> 而对于自定义类型，我们需要自行提供对应的转换函数。</p>
</li>
</ol>
<p>以下这段代码就实现了cv::Mat与json的转换：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 我记得是一定要放在cv这个命名空间里的，否则找不到</span><br><span class="line">namespace cv &#123;</span><br><span class="line">void to_json(nlohmann::json&amp; j, const cv::Mat&amp; p);</span><br><span class="line">void from_json(const nlohmann::json&amp; j, cv::Mat&amp; p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>代码实现很简单，就不讲了~</p>
]]></content>
      <categories>
        <category>RM2022</category>
      </categories>
  </entry>
  <entry>
    <title>人生几何的科研之旅——第一周周报</title>
    <url>/2023/07/02/%E7%AC%AC%E4%B8%80%E5%91%A8%E5%91%A8%E6%8A%A5%E7%9A%84%E5%89%AF%E6%9C%AC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本周主要通过阅读老师推荐的文献，以及一些视频和博客，对小样本图像识别领域经典方法，开放世界小样本学习有了一定的理解。（由于本周有一些课程的大作业，所以时间比较紧张，没来得及看代码）</p>
<h2 id="小样本图像识别领域经典方法"><a href="#小样本图像识别领域经典方法" class="headerlink" title="小样本图像识别领域经典方法"></a>小样本图像识别领域经典方法</h2><p>小样本图像识别是指在数据集较小的情况下，通过一些方法来提高模型的泛化能力，进行图像识别任务</p>
<h3 id="1-数据增强"><a href="#1-数据增强" class="headerlink" title="1.数据增强"></a>1.数据增强</h3><p>数据增强是指通过对训练数据进行一定的变换，生成新的数据来扩充训练集，从而增加数据的多样性和数量。这种方法可以帮助模型更好地学习图像的不变性和鲁棒性，提高模型的泛化能力。常见的数据增强方法包括旋转、平移、缩放、翻转、添加噪声等。</p>
<h3 id="2-元学习"><a href="#2-元学习" class="headerlink" title="2.元学习"></a>2.元学习</h3><p>元学习是学习如何学习的一种方法，它可以在多个任务之间学习，并具有快速适应新任务的能力。在小样本图像识别中，元学习可以帮助模型在仅有几个样本的情况下快速适应新的分类任务。</p>
<h4 id="基于优化的MAML方法"><a href="#基于优化的MAML方法" class="headerlink" title="基于优化的MAML方法"></a>基于优化的MAML方法</h4><p>MAML算法的核心思想是在多个任务之间学习共享知识，通过不断地更新模型参数来适应新的任务。</p>
<h4 id="基于度量的Prototypical-Network方法"><a href="#基于度量的Prototypical-Network方法" class="headerlink" title="基于度量的Prototypical Network方法"></a>基于度量的Prototypical Network方法</h4><p>ProtoNet方法通过计算每个类别的原型向量来进行分类。原型向量是一个类别的所有样本向量的平均值，表示该类别的特征中心。在训练阶段，ProtoNet方法通过计算每个类别的原型向量来学习分类器。在测试阶段，ProtoNet方法通过计算测试样本与每个类别的原型向量的距离来进行分类。</p>
<h4 id="基于度量的DN4方法"><a href="#基于度量的DN4方法" class="headerlink" title="基于度量的DN4方法"></a>基于度量的DN4方法</h4><p>DN4方法的核心思想是提取图像的局部特征，并使用朴素贝叶斯最近邻算法进行相似性度量。</p>
<h3 id="3-预训练-微调"><a href="#3-预训练-微调" class="headerlink" title="3.预训练+微调"></a>3.预训练+微调</h3><p>预训练+微调是指使用大规模图像数据集预训练一个深度学习模型，然后在小样本图像识别任务中微调模型。预训练可以帮助模型学习更好的图像特征，提高模型的泛化能力。在微调过程中，模型会根据小样本图像数据集进行微调，以适应新的分类任务。</p>
<h2 id="开放世界小样本学习"><a href="#开放世界小样本学习" class="headerlink" title="开放世界小样本学习"></a>开放世界小样本学习</h2><p>开放世界小样本学习指的是在小样本学习任务中，考虑到可能存在未知类别的情况，即在测试阶段可能会出现训练集中没有出现过的类别。传统的小样本学习方法只能处理已知类别，无法应对未知类别的情况。</p>
<h3 id="1-跨域小样本学习"><a href="#1-跨域小样本学习" class="headerlink" title="1.跨域小样本学习"></a>1.跨域小样本学习</h3><p>跨域小样本学习（Cross-domain Few-shot Learning）是指在小样本学习任务中，模型需要在训练和测试时处理不同来源的数据集，即跨越不同的数据域。在实际应用中，跨域小样本学习具有广泛的应用场景，如在医学图像识别中利用来自不同医院的数据集进行模型训练和测试。</p>
<h3 id="2-小样本开放集识别"><a href="#2-小样本开放集识别" class="headerlink" title="2.小样本开放集识别"></a>2.小样本开放集识别</h3><p>小样本开放集识别（Few-Shot Open-Set Recognition）是指在小样本学习任务中，模型需要处理未知类别的情况，并且测试集中可能包含已知类别和未知类别两种情况。相比于传统的小样本识别任务，开放集识别任务需要模型具备更强的泛化能力和鲁棒性，因此具有更高的难度和挑战性。</p>
<h3 id="3-通用小样本学习"><a href="#3-通用小样本学习" class="headerlink" title="3.通用小样本学习"></a>3.通用小样本学习</h3><p>通用小样本学习（Generalized Few-shot Learning）是指在小样本学习任务中，模型需要具备在不同任务之间进行迁移学习的能力。相比于传统的小样本学习任务，通用小样本学习任务考虑到了不同任务之间的相似性和差异性。</p>
]]></content>
      <categories>
        <category>科研</category>
        <category>nlp</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>人生几何的科研之旅——第二周周报</title>
    <url>/2023/07/09/%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%91%A8%E6%8A%A5%E7%9A%84%E5%89%AF%E6%9C%AC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="多模态小样本图像识别"><a href="#多模态小样本图像识别" class="headerlink" title="多模态小样本图像识别"></a>多模态小样本图像识别</h3><h4 id="Adaptive-Cross-Modal-Few-shot-Learning"><a href="#Adaptive-Cross-Modal-Few-shot-Learning" class="headerlink" title="Adaptive Cross-Modal Few-shot Learning"></a>Adaptive Cross-Modal Few-shot Learning</h4><h5 id="算法动机："><a href="#算法动机：" class="headerlink" title="算法动机："></a>算法动机：</h5><ul>
<li><p>在图像分类任务上，几乎任何单一模态都有其失效的情况，下面这个图非常直观的说明了这点。这是使用多模态进行图像分类的根本原因。</p>
<p><img src="/images/4.png" alt="Test"></p>
</li>
<li><p>在小样本的情况下，来源于视觉模态的信息是有限的，而semantic语义模态的信息（来自于无监督大规模语料库）可以提供丰富的先验知识和上下文！这是在小样本图像识别任务中引入多模态，特别是语义模态的原因。</p>
</li>
</ul>
<h5 id="算法原理："><a href="#算法原理：" class="headerlink" title="算法原理："></a>算法原理：</h5><ul>
<li><p>总的来说，本文提出的算法其实就是在基于度量的prototypical原型学习基础之上，将原来只包含视觉模态信息的类原型，加权引入了语义模态的信息。如下图所示：</p>
</li>
<li><p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="1.079ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 477 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></mjx-container>将来自语义模态的信息转换到和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="2.019ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 892.2 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g></g></g></svg></mjx-container>相同的维度</p>
</li>
<li><p>其中，h用来计算加权参数，不同的类别，得到的加权参数是不一样的，这可以让模型根据不同类别的特征，选择更好描述该类的模态</p>
<p><img src="/images/5.png" alt="Test"></p>
</li>
</ul>
<h4 id="Learning-Compositional-Representations-for-Few-Shot-Recognition"><a href="#Learning-Compositional-Representations-for-Few-Shot-Recognition" class="headerlink" title="Learning Compositional Representations for Few-Shot Recognition"></a>Learning Compositional Representations for Few-Shot Recognition</h4><h5 id="算法动机：-1"><a href="#算法动机：-1" class="headerlink" title="算法动机："></a>算法动机：</h5><ul>
<li><p>人能够在只有很少目标类别视觉信息的情况下，在很短的时间内掌握该类别的特征，这一能力很可能来源于人脑中含有概念表征的组合结构（the compositional structure of concept representations），即人虽然没有见过该类别，但其能够迅速掌握该类别的一些高级特征（属性）。故此文尝试将图片的一些属性表征同时送入网络，增加信息量。</p>
<p><img src="/images/6.png" alt="Test"></p>
</li>
</ul>
<h5 id="算法特点："><a href="#算法特点：" class="headerlink" title="算法特点："></a>算法特点：</h5><ul>
<li><p>为了提高图像特征提取网络和属性特征提取网络的性能，在损失函数增加了一个软约束使得二者之间尽量相似</p>
<p><img src="/images/7.png" alt="Test"></p>
</li>
<li><p>为了降低各个属性表征之间的相关性，避免出现冗余属性，在损失函数中增加了正交约束</p>
</li>
</ul>
<h3 id="小样本开放集识别"><a href="#小样本开放集识别" class="headerlink" title="小样本开放集识别"></a>小样本开放集识别</h3><h4 id="Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition"><a href="#Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition" class="headerlink" title="Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition"></a>Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition</h4><h5 id="算法动机"><a href="#算法动机" class="headerlink" title="算法动机"></a>算法动机</h5><p>早先针对小样本开放集识别的方法，都是通过设定阈值区分正样本与负样本，该方法存在一些问题：</p>
<ul>
<li><p>首先，该阈值需要人工调整。</p>
</li>
<li><p>其次，不同的任务需要不同的阈值。</p>
</li>
<li><p>同一个任务，我们需要对每一个正样本都设定一个阈值，以便与负样本进行区分，设置起来非常麻烦</p>
<p>所以，文章将阈值调整嵌入模型中，让模型自己学习一个调整函数，根据不同的任务自适应的进行调整。</p>
<p><img src="/images/8.png" alt="Test"></p>
</li>
</ul>
<h5 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h5><ul>
<li><p>该算法设计了一个负样本原型以及阈值生成器，嵌入模型中，在模型的训练过程中进行学习，达到根据不同的任务，自适应阈值的效果。</p>
<p><img src="/images/9.png" alt="Test"></p>
</li>
</ul>
<h3 id="DN4算法复现"><a href="#DN4算法复现" class="headerlink" title="DN4算法复现"></a>DN4算法复现</h3><ul>
<li><h4 id="算法结构"><a href="#算法结构" class="headerlink" title="算法结构!"></a>算法结构!</h4><img src="/images/3.png" alt="Test"></li>
</ul>
<p>DN4是一种基于度量的小样本识别算法</p>
<p>1.首先是一个没有检测头，只有骨干网络的CNN，其作用就是提取图片中的特征，并以特征向量的形式表示</p>
<p>（hw，d），其中hw为特征图的大小，d为特征图的数量（通道数，深度）</p>
<p>2.接着是image-to-Class模块，该模块的作用就是将query image与support set中的images进行相似度度量，并确定其属于哪个类。具体来说，对于support set中的每一个类，我们对query image的每一个局部特征向量，都在support set中该类所有images的所有局部特征向量组成的集合中，使用k近邻算法找出余弦距离最近的k个特征向量，然后求和得到image-to-class（query image to support set中的一个类）的余弦距离总和，那么显然，该图片应该属于该距离最近的类，公式如下：</p>
<p>  <img src="/images/10.png" alt="Test"></p>
<ul>
<li><h4 id="代码实现（基于LibFewShot）"><a href="#代码实现（基于LibFewShot）" class="headerlink" title="代码实现（基于LibFewShot）"></a>代码实现（基于LibFewShot）</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># image-to-Class模块</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        query_feat,</span></span><br><span class="line"><span class="params">        support_feat,</span></span><br><span class="line"><span class="params">        way_num,</span></span><br><span class="line"><span class="params">        shot_num,</span></span><br><span class="line"><span class="params">        query_num,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        t, wq, c, h, w = query_feat.size()</span><br><span class="line">        _, ws, _, _, _ = support_feat.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, c, hw -&gt; t, wq, hw, c -&gt; t, wq, 1, hw, c</span></span><br><span class="line">        query_feat = query_feat.view(t, way_num * query_num, c, h * w).permute(</span><br><span class="line">            <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span></span><br><span class="line">        )</span><br><span class="line">        query_feat = F.normalize(query_feat, p=<span class="number">2</span>, dim=-<span class="number">1</span>).unsqueeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, ws, c, h, w -&gt; t, w, s, c, hw -&gt; t, 1, w, c, shw</span></span><br><span class="line">        support_feat = (</span><br><span class="line">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(t, way_num, c, shot_num * h * w)</span><br><span class="line">        )</span><br><span class="line">        support_feat = F.normalize(support_feat, p=<span class="number">2</span>, dim=<span class="number">2</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class="line">        <span class="comment"># 张量点乘，从算法上可以理解为只有4，5两个维度在做点乘，从功能上，结合上面的归一化操作</span></span><br><span class="line">        <span class="comment"># 这里实际上就是在计算query image和support image中局部特征向量之间的余弦相似度</span></span><br><span class="line">        relation = torch.matmul(query_feat, support_feat)</span><br><span class="line">        <span class="comment"># k近邻算法，只留下距离相近的k个值</span></span><br><span class="line">        topk_value, _ = torch.topk(relation, self.n_k, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 求余弦距离总和，代表image-to-class，即query image和supprot</span></span><br><span class="line">        score = torch.<span class="built_in">sum</span>(topk_value, dim=[<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><span class="line">support_feat = (</span><br><span class="line">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(t, way_num, shot_num * h * w, c)</span><br><span class="line">        )</span><br><span class="line">        support_feat = F.normalize(support_feat, p=<span class="number">2</span>, dim=<span class="number">2</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class="line">        <span class="comment"># relation = torch.matmul(query_feat, support_feat)</span></span><br><span class="line">        <span class="comment"># 改为欧式距离度量相似度，相应的support_feat张量的形状需改变一下</span></span><br><span class="line">        relation = torch.cdist(query_feat, support_feat, p=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></div>


</li>
<li><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><table>
<thead>
<tr>
<th>Shot</th>
<th>dn4-n</th>
<th>相似度衡量</th>
<th>特征图尺寸</th>
<th>测试集准确率</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>3</td>
<td>余弦</td>
<td>$64<em>5</em>5$</td>
<td>30.345%</td>
</tr>
<tr>
<td>5</td>
<td>3</td>
<td>余弦</td>
<td>$64<em>5</em>5$</td>
<td>56.606%</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>余弦</td>
<td>$64<em>5</em>5$</td>
<td>55.148%</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>余弦</td>
<td>$32<em>5</em>5$</td>
<td>51.400%</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>欧式</td>
<td>$32<em>5</em>5$</td>
<td>22.380%</td>
</tr>
</tbody></table>
<p>时间与算力有限，没有做大规模的测试，只做了以上5组</p>
<p>可以发现，shot增加可以使准确率大幅上升，将相似度衡量方法换为欧式距离后准确率大幅下降</p>
<p>而dn4-n和特征图尺寸(主要是通道数/深度d)的变化对测试集影响不大</p>
</li>
</ul>
]]></content>
      <categories>
        <category>科研</category>
        <category>nlp</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>北洋机甲视觉组—Jetson Xavier NX部署过程</title>
    <url>/2023/06/27/nx_deploy/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="开始之前—注意事项"><a href="#开始之前—注意事项" class="headerlink" title="[开始之前—注意事项]"></a>[开始之前—注意事项]</h3><p>本教程只适合于正版NX，如果你使用的是盗版NX，请立即将其扔掉</p>
<h3 id="开始之前—需要的设备"><a href="#开始之前—需要的设备" class="headerlink" title="[开始之前—需要的设备]"></a>[开始之前—需要的设备]</h3><p>1.一台可以科学上网的个人电脑</p>
<p>2.一个NX，以及其充电器</p>
<p>3.一张sd卡（根据自己的电脑查看是否需要读卡器）</p>
<p>4.显示屏，显示屏充电线，充电头</p>
<p>5.连接显示屏与NX的线（NX支持DP&#x2F;Hdmi输出，还需结合你的显示屏支持什么输入）</p>
<p>6.键盘，鼠标</p>
<p>7.沉着，冷静，小心</p>
<h3 id="安装操作系统"><a href="#安装操作系统" class="headerlink" title="[安装操作系统]"></a>[安装操作系统]</h3><p>注意，NX没有内置外存，而是选择让我们使用外接sd卡当作外存。</p>
<h4 id="1-在官网下载镜像"><a href="#1-在官网下载镜像" class="headerlink" title="1. 在官网下载镜像"></a>1. 在官网下载镜像</h4><p><a class="link"   href="https://developer.nvidia.com/embedded/downloads" >nvidia-Jetson下载中心 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>如果要安装18.04的ubuntu，可以选择下载Jetson Xavier NX Developer Kit SD Card Image 4.6</p>
<h4 id="2-将镜像烧录到sd卡中"><a href="#2-将镜像烧录到sd卡中" class="headerlink" title="2. 将镜像烧录到sd卡中"></a>2. 将镜像烧录到sd卡中</h4><p>请参考<a class="link"   href="https://developer.nvidia.com/embedded/learn/get-started-jetson-xavier-nx-devkit#write" >Write Image to the microSD Card <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>根据你的操作系统类型选择不同的方法</p>
<h4 id="3-将sd卡插入NX中，接上电源，开机，设置ubuntu操作系统"><a href="#3-将sd卡插入NX中，接上电源，开机，设置ubuntu操作系统" class="headerlink" title="3. 将sd卡插入NX中，接上电源，开机，设置ubuntu操作系统"></a>3. 将sd卡插入NX中，接上电源，开机，设置ubuntu操作系统</h4><p>注意，为了方便队伍内协同工作，账号密码统一设置为tjurm</p>
<h3 id="安装环境"><a href="#安装环境" class="headerlink" title="[安装环境]"></a>[安装环境]</h3><h4 id="1-联网"><a href="#1-联网" class="headerlink" title="1.联网"></a>1.联网</h4><h4 id="2-换源"><a href="#2-换源" class="headerlink" title="2.换源"></a>2.换源</h4><p>首先，换源需要根据咱们电脑的ubuntu系统版本以及指令集体系结构去进行选择。</p>
<p>查看ubuntu系统版本的方式：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">lsb_release -a</span><br></pre></td></tr></table></figure></div>

<p>查看体系架构的方式：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">uname</span> -m</span><br></pre></td></tr></table></figure></div>

<p>然后根据查找到的这两种信息去CSDN查询</p>
<p>eg： 我们拿到的官方Jetson Xavier NX，应该查询：ubuntu 18.04 arm换源</p>
<p>这里提供快速对ubuntu_18.04_arm进行换源(华为源)的方法：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sudo wget -O /etc/apt/sources.list https://repo.huaweicloud.com/repository/conf/Ubuntu-Ports-bionic.list</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></div>

<h4 id="3-安装jtop"><a href="#3-安装jtop" class="headerlink" title="3.安装jtop"></a>3.安装jtop</h4><p>因为我们需要使用pip3来安装jtop，所以需要在系统中先安装pip3</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure></div>

<p>接着安装jtop</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sudo -H pip3 install -U jetson-stats</span><br></pre></td></tr></table></figure></div>

<p>重启系统</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure></div>

<p>使用jtop</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">jtop</span><br></pre></td></tr></table></figure></div>

<p>查看当前cpu，gpu使用状态（点击最下面一行的2GPU&#x2F;3CPU即可）</p>
<p>设置风扇状态（点击最下面一行的6CTRL，选择manual人工控制，在speed后点击’+‘直到100%）</p>
<h4 id="4-安装大恒相机驱动"><a href="#4-安装大恒相机驱动" class="headerlink" title="4.安装大恒相机驱动"></a>4.安装大恒相机驱动</h4><p><a class="link"   href="https://www.daheng-imaging.com/downloads/" >大恒图像软件下载 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>下载Galaxy Linux-armhf-Gige-U3 SDK_CN-EN 以及  Galaxy Linux-Python SDK_CN-EN</p>
<p>解压后按照readme中提示安装！</p>
<p>注意，Galaxy Linux-armhf-Gige-U3 SDK_CN-EN的安装可能需要输入如下指令：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">bash ./Galaxy_camera.run</span><br></pre></td></tr></table></figure></div>

<p>注意，Galaxy Linux-Python SDK_CN-EN要装适配python3的，在readme文档下面，别装2.7的</p>
<h4 id="5-eigen的安装与软链接"><a href="#5-eigen的安装与软链接" class="headerlink" title="5.eigen的安装与软链接"></a>5.eigen的安装与软链接</h4><p>安装:</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">apt install libeigen3-dev</span><br></pre></td></tr></table></figure></div>

<p>链接：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/include</span><br><span class="line">sudo <span class="built_in">ln</span> -sf eigen3/Eigen Eigen</span><br><span class="line">sudo <span class="built_in">ln</span> -sf eigen3/unsupported unsupported</span><br></pre></td></tr></table></figure></div>

<h4 id="6-从gitee上下载咱们代码"><a href="#6-从gitee上下载咱们代码" class="headerlink" title="6.从gitee上下载咱们代码"></a>6.从gitee上下载咱们代码</h4><p>地址：<a class="link"   href="https://gitee.com/tju-rm-cv" >https://gitee.com/tju-rm-cv <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h4 id="7-vscode安装"><a href="#7-vscode安装" class="headerlink" title="7.vscode安装"></a>7.vscode安装</h4><p>下载debian包，网页打开</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://update.code.visualstudio.com/1.50.1/linux-deb-arm64/stable</span><br></pre></td></tr></table></figure></div>

<p>进入到下载目录，输入：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install ./code...</span><br></pre></td></tr></table></figure></div>

<h4 id="8-ssh配置"><a href="#8-ssh配置" class="headerlink" title="8.ssh配置"></a>8.ssh配置</h4><p>请参照<a class="link"   href="https://blog.csdn.net/weixin_44197719/article/details/119888235" >Ubuntu: 配置ssh，保姆级教程 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，注意这里面要用到vim，请自行学习！</p>
<p>SSH免密登录可以通过在客户端和服务器之间设置公钥认证来实现。具体步骤如下：</p>
<p>在客户端生成公钥和私钥。可以使用以下命令生成：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></div>

<p>该命令将生成一个RSA密钥对，包括公钥和私钥。按照提示输入文件名和密码（可选），如果不需要密码则直接回车即可。</p>
<p>将客户端公钥复制到服务器上的authorized_keys文件中。可以使用以下命令将公钥复制到服务器上：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-copy-id username@servername</span><br></pre></td></tr></table></figure></div>

<p>其中，username是服务器上的用户名，servername是服务器的主机名或IP地址。该命令会将公钥自动添加到服务器上的~&#x2F;.ssh&#x2F;authorized_keys文件中。</p>
<p>这样，就设置完成啦，以后ssh连接就不用输入密码了！</p>
<h4 id="9-ros环境配置"><a href="#9-ros环境配置" class="headerlink" title="9.ros环境配置"></a>9.ros环境配置</h4><p>请参照<a class="link"   href="https://blog.csdn.net/m0_37715028/article/details/106070815" >ROS安装教程(ubuntu18.04+melodic版本) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，建议安装桌面完整版！</p>
<h4 id="10-ros-cv-bridge环境配置"><a href="#10-ros-cv-bridge环境配置" class="headerlink" title="10.ros cv_bridge环境配置"></a>10.ros cv_bridge环境配置</h4><p>请参照<a class="link"   href="https://zhuanlan.zhihu.com/p/392939687" >解决cv_bridge和opencv之间版本匹配问题 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>与<a class="link"   href="https://blog.csdn.net/qq_33980935/article/details/123132452" >Jetson xavier NX &#x2F; ubuntu18.04 &#x2F;ros melodic&#x2F;python3安裝使用cv_bridge <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>ps1:按第一个走的话，在编译的时候会出错，所以在编译前需要按照第二个博客改几个地方！</p>
<p>Ps2:使用cv_bridge的时候一定要按照第一个博客指定cv_bridge的cmake位置！！</p>
]]></content>
      <categories>
        <category>rm</category>
        <category>nvidia</category>
      </categories>
      <tags>
        <tag>rm</tag>
      </tags>
  </entry>
  <entry>
    <title>NX刷机教程</title>
    <url>/2023/04/04/nx_flash/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>直接上结论：使用售后客服的方案awa<br>AI301-KIT<br>链接：<a class="link"   href="https://pan.baidu.com/s/1C8kQRwuMBvJTQuTrBYgwxQ" >https://pan.baidu.com/s/1C8kQRwuMBvJTQuTrBYgwxQ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>提取码：xmu1</p>
]]></content>
      <categories>
        <category>rm</category>
        <category>nvidia</category>
      </categories>
      <tags>
        <tag>rm</tag>
      </tags>
  </entry>
</search>

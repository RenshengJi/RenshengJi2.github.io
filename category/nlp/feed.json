{
    "version": "https://jsonfeed.org/version/1",
    "title": "人生几何 • All posts by \"nlp\" category",
    "description": "",
    "home_page_url": "https://RenshengJi.github.io",
    "items": [
        {
            "id": "https://renshengji.github.io/2023/07/09/week2/",
            "url": "https://renshengji.github.io/2023/07/09/week2/",
            "title": "人生几何的科研之旅——第二周周报",
            "date_published": "2023-07-09T15:48:03.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3 id=\"多模态小样本图像识别\"><a href=\"#多模态小样本图像识别\" class=\"headerlink\" title=\"多模态小样本图像识别\"></a>多模态小样本图像识别</h3><h4 id=\"Adaptive-Cross-Modal-Few-shot-Learning\"><a href=\"#Adaptive-Cross-Modal-Few-shot-Learning\" class=\"headerlink\" title=\"Adaptive Cross-Modal Few-shot Learning\"></a>Adaptive Cross-Modal Few-shot Learning</h4><h5 id=\"算法动机：\"><a href=\"#算法动机：\" class=\"headerlink\" title=\"算法动机：\"></a>算法动机：</h5><ul>\n<li><p>在图像分类任务上，几乎任何单一模态都有其失效的情况，下面这个图非常直观的说明了这点。这是使用多模态进行图像分类的根本原因。</p>\n<p><img src=\"/images/4.png\" alt=\"Test\"></p>\n</li>\n<li><p>在小样本的情况下，来源于视觉模态的信息是有限的，而semantic语义模态的信息（来自于无监督大规模语料库）可以提供丰富的先验知识和上下文！这是在小样本图像识别任务中引入多模态，特别是语义模态的原因。</p>\n</li>\n</ul>\n<h5 id=\"算法原理：\"><a href=\"#算法原理：\" class=\"headerlink\" title=\"算法原理：\"></a>算法原理：</h5><ul>\n<li><p>总的来说，本文提出的算法其实就是在基于度量的prototypical原型学习基础之上，将原来只包含视觉模态信息的类原型，加权引入了语义模态的信息。如下图所示：</p>\n</li>\n<li><p>其中，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.079ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 477 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g></g></g></svg></mjx-container>将来自语义模态的信息转换到和<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.019ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 892.2 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>相同的维度</p>\n</li>\n<li><p>其中，h用来计算加权参数，不同的类别，得到的加权参数是不一样的，这可以让模型根据不同类别的特征，选择更好描述该类的模态</p>\n<p><img src=\"/images/5.png\" alt=\"Test\"></p>\n</li>\n</ul>\n<h4 id=\"Learning-Compositional-Representations-for-Few-Shot-Recognition\"><a href=\"#Learning-Compositional-Representations-for-Few-Shot-Recognition\" class=\"headerlink\" title=\"Learning Compositional Representations for Few-Shot Recognition\"></a>Learning Compositional Representations for Few-Shot Recognition</h4><h5 id=\"算法动机：-1\"><a href=\"#算法动机：-1\" class=\"headerlink\" title=\"算法动机：\"></a>算法动机：</h5><ul>\n<li><p>人能够在只有很少目标类别视觉信息的情况下，在很短的时间内掌握该类别的特征，这一能力很可能来源于人脑中含有概念表征的组合结构（the compositional structure of concept representations），即人虽然没有见过该类别，但其能够迅速掌握该类别的一些高级特征（属性）。故此文尝试将图片的一些属性表征同时送入网络，增加信息量。</p>\n<p><img src=\"/images/6.png\" alt=\"Test\"></p>\n</li>\n</ul>\n<h5 id=\"算法特点：\"><a href=\"#算法特点：\" class=\"headerlink\" title=\"算法特点：\"></a>算法特点：</h5><ul>\n<li><p>为了提高图像特征提取网络和属性特征提取网络的性能，在损失函数增加了一个软约束使得二者之间尽量相似</p>\n<p><img src=\"/images/7.png\" alt=\"Test\"></p>\n</li>\n<li><p>为了降低各个属性表征之间的相关性，避免出现冗余属性，在损失函数中增加了正交约束</p>\n</li>\n</ul>\n<h3 id=\"小样本开放集识别\"><a href=\"#小样本开放集识别\" class=\"headerlink\" title=\"小样本开放集识别\"></a>小样本开放集识别</h3><h4 id=\"Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition\"><a href=\"#Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition\" class=\"headerlink\" title=\"Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition\"></a>Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition</h4><h5 id=\"算法动机\"><a href=\"#算法动机\" class=\"headerlink\" title=\"算法动机\"></a>算法动机</h5><p>早先针对小样本开放集识别的方法，都是通过设定阈值区分正样本与负样本，该方法存在一些问题：</p>\n<ul>\n<li><p>首先，该阈值需要人工调整。</p>\n</li>\n<li><p>其次，不同的任务需要不同的阈值。</p>\n</li>\n<li><p>同一个任务，我们需要对每一个正样本都设定一个阈值，以便与负样本进行区分，设置起来非常麻烦</p>\n<p>所以，文章将阈值调整嵌入模型中，让模型自己学习一个调整函数，根据不同的任务自适应的进行调整。</p>\n<p><img src=\"/images/8.png\" alt=\"Test\"></p>\n</li>\n</ul>\n<h5 id=\"算法原理\"><a href=\"#算法原理\" class=\"headerlink\" title=\"算法原理\"></a>算法原理</h5><ul>\n<li><p>该算法设计了一个负样本原型以及阈值生成器，嵌入模型中，在模型的训练过程中进行学习，达到根据不同的任务，自适应阈值的效果。</p>\n<p><img src=\"/images/9.png\" alt=\"Test\"></p>\n</li>\n</ul>\n<h3 id=\"DN4算法复现\"><a href=\"#DN4算法复现\" class=\"headerlink\" title=\"DN4算法复现\"></a>DN4算法复现</h3><ul>\n<li><h4 id=\"算法结构\"><a href=\"#算法结构\" class=\"headerlink\" title=\"算法结构!\"></a>算法结构!</h4><img src=\"/images/3.png\" alt=\"Test\"></li>\n</ul>\n<p>DN4是一种基于度量的小样本识别算法</p>\n<p>1.首先是一个没有检测头，只有骨干网络的CNN，其作用就是提取图片中的特征，并以特征向量的形式表示</p>\n<p>（hw，d），其中hw为特征图的大小，d为特征图的数量（通道数，深度）</p>\n<p>2.接着是image-to-Class模块，该模块的作用就是将query image与support set中的images进行相似度度量，并确定其属于哪个类。具体来说，对于support set中的每一个类，我们对query image的每一个局部特征向量，都在support set中该类所有images的所有局部特征向量组成的集合中，使用k近邻算法找出余弦距离最近的k个特征向量，然后求和得到image-to-class（query image to support set中的一个类）的余弦距离总和，那么显然，该图片应该属于该距离最近的类，公式如下：</p>\n<p>  <img src=\"/images/10.png\" alt=\"Test\"></p>\n<ul>\n<li><h4 id=\"代码实现（基于LibFewShot）\"><a href=\"#代码实现（基于LibFewShot）\" class=\"headerlink\" title=\"代码实现（基于LibFewShot）\"></a>代码实现（基于LibFewShot）</h4><div class=\"highlight-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># image-to-Class模块</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">        self,</span></span><br><span class=\"line\"><span class=\"params\">        query_feat,</span></span><br><span class=\"line\"><span class=\"params\">        support_feat,</span></span><br><span class=\"line\"><span class=\"params\">        way_num,</span></span><br><span class=\"line\"><span class=\"params\">        shot_num,</span></span><br><span class=\"line\"><span class=\"params\">        query_num,</span></span><br><span class=\"line\"><span class=\"params\">    </span>):</span><br><span class=\"line\">        t, wq, c, h, w = query_feat.size()</span><br><span class=\"line\">        _, ws, _, _, _ = support_feat.size()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># t, wq, c, hw -&gt; t, wq, hw, c -&gt; t, wq, 1, hw, c</span></span><br><span class=\"line\">        query_feat = query_feat.view(t, way_num * query_num, c, h * w).permute(</span><br><span class=\"line\">            <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">        query_feat = F.normalize(query_feat, p=<span class=\"number\">2</span>, dim=-<span class=\"number\">1</span>).unsqueeze(<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># t, ws, c, h, w -&gt; t, w, s, c, hw -&gt; t, 1, w, c, shw</span></span><br><span class=\"line\">        support_feat = (</span><br><span class=\"line\">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class=\"line\">            .permute(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">            .contiguous()</span><br><span class=\"line\">            .view(t, way_num, c, shot_num * h * w)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        support_feat = F.normalize(support_feat, p=<span class=\"number\">2</span>, dim=<span class=\"number\">2</span>).unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class=\"line\">        <span class=\"comment\"># 张量点乘，从算法上可以理解为只有4，5两个维度在做点乘，从功能上，结合上面的归一化操作</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里实际上就是在计算query image和support image中局部特征向量之间的余弦相似度</span></span><br><span class=\"line\">        relation = torch.matmul(query_feat, support_feat)</span><br><span class=\"line\">        <span class=\"comment\"># k近邻算法，只留下距离相近的k个值</span></span><br><span class=\"line\">        topk_value, _ = torch.topk(relation, self.n_k, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 求余弦距离总和，代表image-to-class，即query image和supprot</span></span><br><span class=\"line\">        score = torch.<span class=\"built_in\">sum</span>(topk_value, dim=[<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> score</span><br></pre></td></tr></table></figure></div>\n\n<div class=\"highlight-container\" data-rel=\"Python\"><figure class=\"iseeu highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">support_feat = (</span><br><span class=\"line\">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class=\"line\">            .permute(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">            .contiguous()</span><br><span class=\"line\">            .view(t, way_num, shot_num * h * w, c)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        support_feat = F.normalize(support_feat, p=<span class=\"number\">2</span>, dim=<span class=\"number\">2</span>).unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class=\"line\">        <span class=\"comment\"># relation = torch.matmul(query_feat, support_feat)</span></span><br><span class=\"line\">        <span class=\"comment\"># 改为欧式距离度量相似度，相应的support_feat张量的形状需改变一下</span></span><br><span class=\"line\">        relation = torch.cdist(query_feat, support_feat, p=<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure></div>\n\n\n</li>\n<li><h4 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h4><table>\n<thead>\n<tr>\n<th>Shot</th>\n<th>dn4-n</th>\n<th>相似度衡量</th>\n<th>特征图尺寸</th>\n<th>测试集准确率</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>3</td>\n<td>余弦</td>\n<td>$64<em>5</em>5$</td>\n<td>30.345%</td>\n</tr>\n<tr>\n<td>5</td>\n<td>3</td>\n<td>余弦</td>\n<td>$64<em>5</em>5$</td>\n<td>56.606%</td>\n</tr>\n<tr>\n<td>5</td>\n<td>5</td>\n<td>余弦</td>\n<td>$64<em>5</em>5$</td>\n<td>55.148%</td>\n</tr>\n<tr>\n<td>5</td>\n<td>5</td>\n<td>余弦</td>\n<td>$32<em>5</em>5$</td>\n<td>51.400%</td>\n</tr>\n<tr>\n<td>5</td>\n<td>5</td>\n<td>欧式</td>\n<td>$32<em>5</em>5$</td>\n<td>22.380%</td>\n</tr>\n</tbody></table>\n<p>时间与算力有限，没有做大规模的测试，只做了以上5组</p>\n<p>可以发现，shot增加可以使准确率大幅上升，将相似度衡量方法换为欧式距离后准确率大幅下降</p>\n<p>而dn4-n和特征图尺寸(主要是通道数/深度d)的变化对测试集影响不大</p>\n</li>\n</ul>\n",
            "tags": [
                "科研"
            ]
        },
        {
            "id": "https://renshengji.github.io/2023/07/09/week3/",
            "url": "https://renshengji.github.io/2023/07/09/week3/",
            "title": "人生几何的科研之旅——第三周周报",
            "date_published": "2023-07-09T15:48:03.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"分析上周DN4算法复现中存在的问题\"><a href=\"#分析上周DN4算法复现中存在的问题\" class=\"headerlink\" title=\"分析上周DN4算法复现中存在的问题\"></a>分析上周DN4算法复现中存在的问题</h2><p>没有查看原论文中对实验的设置，且没有与论文中的实验结果进行比较</p>\n<ul>\n<li>原论文明确指出了1-shot和5-shot情况下查询集的图像数量</li>\n<li>原论文明确指出了在训练和验证时的episodes数量，</li>\n<li>原论文明确指出了在训练时需要使用 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.392ex\" height=\"2.003ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -863.3 3709.1 885.3\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1722.4,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1033,393.1) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></g></g></svg></mjx-container> 的初始学习率，以及每100000个episodes进行学习率减半。</li>\n</ul>\n<p>经过调整，重新进行实验，得到了与原论文一致的实验结果：</p>\n<p><img src=\"/images/1/1-1.png\" alt=\"截屏2023-07-10 13.46.41\"></p>\n<h2 id=\"继续阅读小样本开放集识别论文\"><a href=\"#继续阅读小样本开放集识别论文\" class=\"headerlink\" title=\"继续阅读小样本开放集识别论文\"></a>继续阅读小样本开放集识别论文</h2><h3 id=\"Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition\"><a href=\"#Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition\" class=\"headerlink\" title=\"Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition\"></a>Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition</h3><p><a class=\"link\" href=\"https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.pdf\">原文链接 <i class=\"fa-regular fa-arrow-up-right-from-square fa-sm\"></i></a></p>\n<h4 id=\"算法原理\"><a href=\"#算法原理\" class=\"headerlink\" title=\"算法原理\"></a>算法原理</h4><p>接续上周的阅读，本周主要阅读了本篇论文中关于负类原型生成器（Negative Generator，即根据已知类原型生成未知类原型，用于生成任务自适应阈值）的部分，下面是本文介绍的几种方法：</p>\n<ul>\n<li><p><strong>MLP</strong>：首先将所有已知类的原型 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"9.235ex\" height=\"2.388ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 4081.9 1055.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g><g data-mml-node=\"mtext\" transform=\"translate(892.2,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1142.2,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1853,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2797.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(845.3,363) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></g></svg></mjx-container> 求平均得到 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.887ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.711ex\" height=\"2.641ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -775.2 1640.3 1167.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msubsup\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(536,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(536,-247) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(529,0)\"><path data-c=\"1D463\" d=\"M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1014,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g></g></g></g></g></svg></mjx-container>，再输入mlp，输出负类原型 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.57ex\" height=\"2.193ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -775.2 1136.1 969.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(536,363) scale(0.707)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g></g></g></g></svg></mjx-container>。</p>\n<p><img src=\"/images/1/1-2.png\" alt=\"截屏2023-07-10 13.46.41\"></p>\n</li>\n<li><p><strong>ATT</strong>：上述MLP的方法并<strong>没有考虑已知类原型之间的关系</strong>，故引入了在Transformer上效果显著的<strong>自注意力机制</strong>，考虑各类原型之间的关系，公式如下，最终负类原型 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.056ex\" height=\"2.32ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -775.2 5328.9 1025.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(536,363) scale(0.707)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1413.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2469.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3466.9,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(3855.9,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4939.9,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container></p>\n<p><img src=\"/images/1/1-3.png\" alt=\"1\"><img src=\"/images/1/1-4.png\" alt=\"1\"></p>\n</li>\n<li><p><strong>ATT-G</strong>：一种基于ATT的，扩展应用到GFSOR，<u>通用小样本开放集识别</u>（已知类不仅有few-shot类，还有传统的many-shot类）问题的方法。</p>\n<ul>\n<li><p>一方面，其将ATT的针对 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.892ex\" height=\"1.949ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 1278.4 861.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></g></svg></mjx-container>（few-shot类原型）的自注意力模块，换为了针对 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.892ex\" height=\"1.949ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 1278.4 861.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></g></svg></mjx-container>和 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.812ex\" height=\"1.565ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -691.8 1243 691.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g></g></g></svg></mjx-container>（many-shot类原型）的互注意力模块，公式如下：<img src=\"/images/1/1-5.png\" alt=\"1\"></p>\n</li>\n<li><p>另一方面，其为了减少任务无关信息的干扰，引入了<strong>通道门控机制</strong>（channel-wise gating mechanism），经查询，这是一种在CNN中常用的机制，它通过控制卷积层中每个通道的权重来影响该通道对输出的贡献，这种机制可以用来控制网络的运算速度和精度，也可以用来提高网络的鲁棒性和泛化能力。在这里，利用该机制（通过提高任务相关通道对输出的贡献，降低任务无关通道对输出的贡献），可以达到减少任务无关信息干扰的作用！如下 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.576ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.019ex\" height=\"2.294ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -759 892.2 1013.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msubsup\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(536,363) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-247) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>为将一个few-shot类减少任务无关信息之后的原型：<img src=\"/images/1/1-6.png\" alt=\"1\"></p>\n<p>其中，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.667ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.059ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 910.3 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g></g></g></g></svg></mjx-container>的输入为few-shot类中其他所有类的均值，输出是什么文章中并没有说，但是我认为应该是能代表这些类的，维度和 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.019ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 892.2 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>一样的原型（此时该原型应该大致代表了该任务？），然后再经过softmax操作，再与 <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.019ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 892.2 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>做点乘（element-wise multipli- cation），就能减少该类中任务无关的信息。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>SEMAN-G</strong>：一种基于ATT-G的，结合标签语义信息的一种多模态方法。具体的，其在计算注意力矩阵<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.86ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.608ex\" height=\"2.48ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 3362.6 1096\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,-203.3) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(839.5,289) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1667.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1945.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(839.5,289) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3188.4,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></g></svg></mjx-container>时，将<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.471ex\" height=\"2.515ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 3744 1111.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1667.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2112,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(839.5,363) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3355,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container> 换为带标签语义信息的<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.328ex\" height=\"2.515ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -861.5 3681.1 1111.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44D\" d=\"M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(808,363) scale(0.707)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1635.9,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2080.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44D\" d=\"M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(808,363) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3292.1,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.167ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 4935.8 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D467\" d=\"M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(498,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1132,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2187.7,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2465.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(536,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3357.9,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3802.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(499,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4657.8,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></svg></mjx-container>，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.935ex\" height=\"1.357ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 855.2 599.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(499,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>为由标签语义转换而来的词嵌入向量。</p>\n</li>\n</ul>\n<h3 id=\"Few-shot-Open-set-Recognition-Using-Background-as-Unknowns\"><a href=\"#Few-shot-Open-set-Recognition-Using-Background-as-Unknowns\" class=\"headerlink\" title=\"Few-shot Open-set Recognition Using Background as Unknowns\"></a>Few-shot Open-set Recognition Using Background as Unknowns</h3><h4 id=\"算法动机\"><a href=\"#算法动机\" class=\"headerlink\" title=\"算法动机\"></a>算法动机</h4><ul>\n<li><p>在闭集分类任务（N类）中，我们通常会将嵌入空间（embedding space）分为N块，但这些区块的边界都是根据封闭集中的已知类别之间的区别得到的，这样的话，就会导致新的没有见过的类被错误的分到已知类中。故本文想到了要构造出Unknown类，结合已知类对嵌入空间进行划分，留出Unknown类的区块。</p>\n<p><img src=\"/images/1/1-7.png\" alt=\"1\"></p>\n</li>\n<li><p>之前的研究中，构造Unknown类的办法是利用GAN生成对抗网络，但是这种方法费时间，需要在网络中添加额外的分支，工作。</p>\n</li>\n<li><p>本文发现相比于前景，图片的背景对分类的结果影响甚微，故想到了将图片的背景提取出来，作为Unknown类。如下图所示，红色部分是对分类结果影响最大的部分，而这一部分往往是前景。</p>\n<p><img src=\"/images/1/1-11.png\" alt=\"1\"></p>\n<p>个人感觉将背景类当作unseen类的这种想法有点离谱，一方面是直觉awa，另一方面是以前听说过有些时候，图片的背景和前景是存在某种关联的。</p>\n</li>\n</ul>\n<h4 id=\"算法原理-1\"><a href=\"#算法原理-1\" class=\"headerlink\" title=\"算法原理\"></a>算法原理</h4><ul>\n<li>如图所示为模型的整体结构，支持集图片和查询集图片经过同一个骨干网络生成特征图，接着查询集的特征图直接经过嵌入函数得到一个描述当前查询集图像的特征向量，而支持集需通过ProCAM方法得到背景，接着再和特征图一起经过嵌入函数得到描述当前支持集图片前景和背景类别的参数矩阵，最后将查询集的特征向量和支持集的参数矩阵进行余弦相似度度量，得到查询集的类别。</li>\n</ul>\n<p><img src=\"/images/1/1-8.png\" alt=\"1\"></p>\n<ul>\n<li><p>本模型训练过程的损失计算包含四个部分，如下图所示，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.435ex\" height=\"1.952ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1076.3 862.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(723,-150) scale(0.707)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g></g></svg></mjx-container>指的是支持集的损失，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.549ex\" height=\"1.97ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1126.6 870.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(723,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></g></svg></mjx-container>指的是图像（前景）类别的损失，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.549ex\" height=\"1.934ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1126.6 855\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(723,-150) scale(0.707)\"><path data-c=\"34\" d=\"M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z\"></path></g></g></g></g></svg></mjx-container>指的是图像背景类别的损失。<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.73ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 2974.7 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(690,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1079,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1651,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2095.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2585.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>指的是查询集的损失，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.549ex\" height=\"1.934ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1126.6 855\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(723,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>指的是当查询集图像为已知类时的损失，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.549ex\" height=\"1.934ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 1126.6 855\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"4C\" d=\"M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(723,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container>指的则是图像为unseen类时的损失。</p>\n<p><img src=\"/images/1/1-9.png\" alt=\"1\"></p>\n<p><img src=\"/images/1/1-10.png\" alt=\"1\"></p>\n</li>\n<li><p>值得注意的是，本文中并没有对训练集中每一张图片其中背景类别，或者说unseen类别进行标注，而只是确定了有几个unseen类，且采用如下公式对unseen类别的标签进行估计，论文中并没有对此做多讲解，个人猜测作者的意思可能是通过这种方法计算loss，可以让unseen类尽可能的真正落到unseen类别中，且通过训练进行自适应归类。</p>\n</li>\n</ul>\n<p><img src=\"/images/1/1-12.png\" alt=\"1\"></p>\n<h3 id=\"Few-Shot-Open-Set-Recognition-using-Meta-Learning\"><a href=\"#Few-Shot-Open-Set-Recognition-using-Meta-Learning\" class=\"headerlink\" title=\"Few-Shot Open-Set Recognition using Meta-Learning\"></a>Few-Shot Open-Set Recognition using Meta-Learning</h3><h4 id=\"算法动机-1\"><a href=\"#算法动机-1\" class=\"headerlink\" title=\"算法动机\"></a>算法动机</h4><ul>\n<li>很多小样本开放集识别方法中，都将所有的unseen类归结到一类中，即在嵌入空间中只用一块区间表示所有的负类，比如说TANE方法学习一个负类原型，本文认为这种方法比较困难。相反，本文并没有考虑去表示unseen类，而是将seen类进行更好的聚类，特征提取，将不属于seen类的归于unseen类，本文中相信这是一种拒绝unseen类中的更自然，合理的方式。 </li>\n<li>元学习ML本是小样本识别任务中的一种方法，但是其很容易迁移到小样本开放集识别的任务中。</li>\n</ul>\n<h4 id=\"算法原理-2\"><a href=\"#算法原理-2\" class=\"headerlink\" title=\"算法原理\"></a>算法原理</h4><ul>\n<li>首先，本文算法基于元学习的基本流程，只是在meta-test过程中加入了unseen类作为输入</li>\n</ul>\n<p><img src=\"/images/1/1-13.png\" alt=\"1\"></p>\n<ul>\n<li>相应的，这里的损失计算函数需要更新，如下公式，其中<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.421ex\" height=\"1.902ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1070.2 840.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D43F\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(714,-150) scale(0.707)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></g></svg></mjx-container>是计算seen类的损失，<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.504ex\" height=\"1.902ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1106.9 840.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D43F\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(714,-150) scale(0.707)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g></g></g></g></svg></mjx-container>计算unseen类的损失。</li>\n</ul>\n<p><img src=\"/images/1/1-14.png\" alt=\"1\"></p>\n<ul>\n<li>对于已知类别，我们采用改造后的，基于度量学习的softmax计算交叉熵损失，如下公式：</li>\n</ul>\n<p><img src=\"/images/1/1-15.png\" alt=\"1\"><img src=\"/images/1/1-16.png\" alt=\"1\"></p>\n<ul>\n<li>对于unseen类，我们引入了<strong>负熵</strong>计算loss，经过查询，负熵这一词最初是信息论中的概念，用来评价一个概率分布与高斯分布之间的相似度，公式为<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.777ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"28.101ex\" height=\"2.563ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -789.6 12420.8 1132.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(888,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1277,0)\"><path data-c=\"1D44B\" d=\"M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2129,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2795.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"munderover\" transform=\"translate(3851.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1089,477.1) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(1089,-285.4) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(345,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1123,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(6304.9,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(751,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1140,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2039,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2428,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2726,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3211,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3688,0)\"><path data-c=\"1D443\" d=\"M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4439,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4828,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5726.9,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></svg></mjx-container> ，根据公式我们发现，如果经过softmax后收敛到某个结果（在某个<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.034ex\" height=\"1.357ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 899 599.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>上概率逼近1，而在别的情况下概率几乎为0），那么负熵将趋紧于0，而如果经过softmax后，各个结果的概率相等，则负熵就会是一个绝对值比较大的负值。所以，负熵在这里可以用来计算unseen类的loss！<img src=\"/images/1/1-17.png\" alt=\"1\"></li>\n</ul>\n",
            "tags": [
                "科研"
            ]
        },
        {
            "id": "https://renshengji.github.io/2023/07/02/week1/",
            "url": "https://renshengji.github.io/2023/07/02/week1/",
            "title": "人生几何的科研之旅——第一周周报",
            "date_published": "2023-07-02T15:48:03.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本周主要通过阅读老师推荐的文献，以及一些视频和博客，对小样本图像识别领域经典方法，开放世界小样本学习有了一定的理解。（由于本周有一些课程的大作业，所以时间比较紧张，没来得及看代码）</p>\n<h2 id=\"小样本图像识别领域经典方法\"><a href=\"#小样本图像识别领域经典方法\" class=\"headerlink\" title=\"小样本图像识别领域经典方法\"></a>小样本图像识别领域经典方法</h2><p>小样本图像识别是指在数据集较小的情况下，通过一些方法来提高模型的泛化能力，进行图像识别任务</p>\n<h3 id=\"1-数据增强\"><a href=\"#1-数据增强\" class=\"headerlink\" title=\"1.数据增强\"></a>1.数据增强</h3><p>数据增强是指通过对训练数据进行一定的变换，生成新的数据来扩充训练集，从而增加数据的多样性和数量。这种方法可以帮助模型更好地学习图像的不变性和鲁棒性，提高模型的泛化能力。常见的数据增强方法包括旋转、平移、缩放、翻转、添加噪声等。</p>\n<h3 id=\"2-元学习\"><a href=\"#2-元学习\" class=\"headerlink\" title=\"2.元学习\"></a>2.元学习</h3><p>元学习是学习如何学习的一种方法，它可以在多个任务之间学习，并具有快速适应新任务的能力。在小样本图像识别中，元学习可以帮助模型在仅有几个样本的情况下快速适应新的分类任务。</p>\n<h4 id=\"基于优化的MAML方法\"><a href=\"#基于优化的MAML方法\" class=\"headerlink\" title=\"基于优化的MAML方法\"></a>基于优化的MAML方法</h4><p>MAML算法的核心思想是在多个任务之间学习共享知识，通过不断地更新模型参数来适应新的任务。</p>\n<h4 id=\"基于度量的Prototypical-Network方法\"><a href=\"#基于度量的Prototypical-Network方法\" class=\"headerlink\" title=\"基于度量的Prototypical Network方法\"></a>基于度量的Prototypical Network方法</h4><p>ProtoNet方法通过计算每个类别的原型向量来进行分类。原型向量是一个类别的所有样本向量的平均值，表示该类别的特征中心。在训练阶段，ProtoNet方法通过计算每个类别的原型向量来学习分类器。在测试阶段，ProtoNet方法通过计算测试样本与每个类别的原型向量的距离来进行分类。</p>\n<h4 id=\"基于度量的DN4方法\"><a href=\"#基于度量的DN4方法\" class=\"headerlink\" title=\"基于度量的DN4方法\"></a>基于度量的DN4方法</h4><p>DN4方法的核心思想是提取图像的局部特征，并使用朴素贝叶斯最近邻算法进行相似性度量。</p>\n<h3 id=\"3-预训练-微调\"><a href=\"#3-预训练-微调\" class=\"headerlink\" title=\"3.预训练+微调\"></a>3.预训练+微调</h3><p>预训练+微调是指使用大规模图像数据集预训练一个深度学习模型，然后在小样本图像识别任务中微调模型。预训练可以帮助模型学习更好的图像特征，提高模型的泛化能力。在微调过程中，模型会根据小样本图像数据集进行微调，以适应新的分类任务。</p>\n<h2 id=\"开放世界小样本学习\"><a href=\"#开放世界小样本学习\" class=\"headerlink\" title=\"开放世界小样本学习\"></a>开放世界小样本学习</h2><p>开放世界小样本学习指的是在小样本学习任务中，考虑到可能存在未知类别的情况，即在测试阶段可能会出现训练集中没有出现过的类别。传统的小样本学习方法只能处理已知类别，无法应对未知类别的情况。</p>\n<h3 id=\"1-跨域小样本学习\"><a href=\"#1-跨域小样本学习\" class=\"headerlink\" title=\"1.跨域小样本学习\"></a>1.跨域小样本学习</h3><p>跨域小样本学习（Cross-domain Few-shot Learning）是指在小样本学习任务中，模型需要在训练和测试时处理不同来源的数据集，即跨越不同的数据域。在实际应用中，跨域小样本学习具有广泛的应用场景，如在医学图像识别中利用来自不同医院的数据集进行模型训练和测试。</p>\n<h3 id=\"2-小样本开放集识别\"><a href=\"#2-小样本开放集识别\" class=\"headerlink\" title=\"2.小样本开放集识别\"></a>2.小样本开放集识别</h3><p>小样本开放集识别（Few-Shot Open-Set Recognition）是指在小样本学习任务中，模型需要处理未知类别的情况，并且测试集中可能包含已知类别和未知类别两种情况。相比于传统的小样本识别任务，开放集识别任务需要模型具备更强的泛化能力和鲁棒性，因此具有更高的难度和挑战性。</p>\n<h3 id=\"3-通用小样本学习\"><a href=\"#3-通用小样本学习\" class=\"headerlink\" title=\"3.通用小样本学习\"></a>3.通用小样本学习</h3><p>通用小样本学习（Generalized Few-shot Learning）是指在小样本学习任务中，模型需要具备在不同任务之间进行迁移学习的能力。相比于传统的小样本学习任务，通用小样本学习任务考虑到了不同任务之间的相似性和差异性。</p>\n",
            "tags": [
                "科研"
            ]
        }
    ]
}
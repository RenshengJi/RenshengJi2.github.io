<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="keywords" content="Hexo Theme Redefine"><meta name="description" content="Hexo Theme Redefine"><meta name="author" content="人生几何"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-redefine.png"><link rel="canonical" href="https://RenshengJi.github.io/2023/07/09/week2/"><meta name="robots" content="index,follow"><meta name="googlebot" content="index,follow"><meta name="revisit-after" content="1 days"><meta property="og:type" content="article"><meta property="og:title" content="人生几何的科研之旅——第二周周报"><meta property="og:description" content="Hexo Theme Redefine"><meta property="og:url" content="https://RenshengJi.github.io2023/07/09/week2/"><meta property="og:image" content="/images/redefine-logo.svg"><meta property="og:site_name" content="人生几何"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="人生几何的科研之旅——第二周周报"><meta name="twitter:description" content="Hexo Theme Redefine"><meta name="twitter:image" content="/images/redefine-logo.svg"><link rel="icon" type="image/png" href="/images/redefine-logo.svg" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/images/redefine-logo.svg"><meta name="theme-color" content="#005080"><link rel="shortcut icon" href="/images/redefine-logo.svg"><title>人生几何的科研之旅——第二周周报 - 人生几何</title><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/assets/fonts.css"><link rel="preconnect" href="https://evan.beee.top" crossorigin><script id="hexo-configurations">let REDEFINE=window.REDEFINE||{};REDEFINE.hexo_config={hostname:"renshengji.github.io",root:"/",language:"zh-CN",path:"search.xml"},REDEFINE.theme_config={toc:{enable:!0,number:!1,expand_all:!0,init_open:!0},style:{primary_color:"#005080",avatar:"/images/2.jpg",favicon:"/images/redefine-logo.svg",article_img_align:"center",right_side_width:"210px",content_max_width:"1000px",nav_color:{left:"#f78736",right:"#367df7",transparency:35},hover:{shadow:!0,scale:!1},first_screen:{enable:!0,background_image:{light:"https://evan.beee.top/img/wallhaven-wqery6-light.webp",dark:"https://evan.beee.top/img/wallhaven-wqery6-dark.webp"},title_color:{light:"#fff",dark:"#d1d1b6"},description:"人生几何，岁月如歌",custom_font:{enable:!1,font_family:null,font_url:null}},scroll:{progress_bar:{enable:!0},percent:{enable:!1}}},local_search:{enable:!0,preload:!0},code_block:{copy:!0,style:"mac",custom_font:{enable:!1,font_family:null,font_url:null}},pjax:{enable:!0},lazyload:{enable:!1},version:"1.2.1",friend_links:{columns:2},home_article:{date_format:"auto",category:{enable:!0,limit:3},tag:{enable:!0,limit:3}}},REDEFINE.language_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"}</script><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/fontawesome/fontawesome.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/fontawesome/brands.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/fontawesome/solid.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/fontawesome/regular.min.css"><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span> <span class="pjax-progress-icon"><i class="fa-solid fa-circle-notch fa-spin"></i></span></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="menu-wrapper"><div class="menu-content"><div class="left"><a class="logo-title" href="/">人生几何</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/"><i class="fa-regular fa-house"></i> 首页</a></li><li class="menu-item"><a href="/categories"><i class="fa-regular fa-archive"></i> 归档</a></li><li class="menu-item"><a href="/playlists"><i class="fa-regular fa-archive"></i> 关于</a></li><li class="menu-item"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-regular fa-link"></i> 友链&nbsp;<i class="fa-solid fa-chevron-down"></i></a><ul class="sub-menu"><li><a href="/link1">LINK1</a></li><li><a href="/link2">LINK2</a></li><li><a href="/link3">LINK3</a></li></ul></li><li class="menu-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="menu-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/"><i class="fa-regular fa-house"></i> 首页</a></li><li class="drawer-menu-item flex-center"><a href="/categories"><i class="fa-regular fa-archive"></i> 归档</a></li><li class="drawer-menu-item flex-center"><a href="/playlists"><i class="fa-regular fa-archive"></i> 关于</a></li><li class="drawer-menu-item flex-center"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-regular fa-link"></i> 友链&nbsp;<i class="fa-solid fa-chevron-down"></i></a></li><li class="dropdown-item flex-center"><a class="dropdown-item" href="/link1">LINK1</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" href="/link2">LINK2</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" href="/link3">LINK3</a></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="post-page-container"><div class="article-content-container"><div class="article-title"><img src="/images/3.png" alt="人生几何的科研之旅——第二周周报"><h1 class="article-title-cover">人生几何的科研之旅——第二周周报</h1></div><div class="article-header"><div class="avatar"><img src="/images/2.jpg"></div><div class="info"><div class="author"><span class="name">人生几何</span> <span class="author-label">lol</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-pen-fancy"></i>&nbsp; <span class="pc">2023-07-09 23:48:03</span> <span class="mobile">2023-07-09 23:48</span> <span class="hover-info">创建时间</span> </span><span class="article-date article-meta-item"><i class="fa-regular fa-wrench"></i>&nbsp; <span class="pc">2023-07-15 16:57:25</span> <span class="mobile">2023-07-15 16:57</span> <span class="hover-info">更新时间</span> </span><span class="article-categories article-meta-item"><i class="fa-regular fa-folders"></i>&nbsp;<ul><li><a href="/categories/%E7%A7%91%E7%A0%94/">科研</a>&nbsp;</li><li>&gt; <a href="/categories/%E7%A7%91%E7%A0%94/FSOR/">FSOR</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fa-regular fa-tags"></i>&nbsp;<ul><li><a href="/tags/%E7%A7%91%E7%A0%94/">科研</a>&nbsp;</li></ul></span><span class="article-pv article-meta-item"><i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body"><h3 id="多模态小样本图像识别"><a href="#多模态小样本图像识别" class="headerlink" title="多模态小样本图像识别"></a>多模态小样本图像识别</h3><h4 id="Adaptive-Cross-Modal-Few-shot-Learning"><a href="#Adaptive-Cross-Modal-Few-shot-Learning" class="headerlink" title="Adaptive Cross-Modal Few-shot Learning"></a>Adaptive Cross-Modal Few-shot Learning</h4><h5 id="算法动机："><a href="#算法动机：" class="headerlink" title="算法动机："></a>算法动机：</h5><ul><li><p>在图像分类任务上，几乎任何单一模态都有其失效的情况，下面这个图非常直观的说明了这点。这是使用多模态进行图像分类的根本原因。</p><p><img src="/images/4.png" alt="Test"></p></li><li><p>在小样本的情况下，来源于视觉模态的信息是有限的，而semantic语义模态的信息（来自于无监督大规模语料库）可以提供丰富的先验知识和上下文！这是在小样本图像识别任务中引入多模态，特别是语义模态的原因。</p></li></ul><h5 id="算法原理："><a href="#算法原理：" class="headerlink" title="算法原理："></a>算法原理：</h5><ul><li><p>总的来说，本文提出的算法其实就是在基于度量的prototypical原型学习基础之上，将原来只包含视觉模态信息的类原型，加权引入了语义模态的信息。如下图所示：</p></li><li><p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.464ex" xmlns="http://www.w3.org/2000/svg" width="1.079ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 477 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g></g></svg></mjx-container>将来自语义模态的信息转换到和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="2.019ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 892.2 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g></g></g></g></svg></mjx-container>相同的维度</p></li><li><p>其中，h用来计算加权参数，不同的类别，得到的加权参数是不一样的，这可以让模型根据不同类别的特征，选择更好描述该类的模态</p><p><img src="/images/5.png" alt="Test"></p></li></ul><h4 id="Learning-Compositional-Representations-for-Few-Shot-Recognition"><a href="#Learning-Compositional-Representations-for-Few-Shot-Recognition" class="headerlink" title="Learning Compositional Representations for Few-Shot Recognition"></a>Learning Compositional Representations for Few-Shot Recognition</h4><h5 id="算法动机：-1"><a href="#算法动机：-1" class="headerlink" title="算法动机："></a>算法动机：</h5><ul><li><p>人能够在只有很少目标类别视觉信息的情况下，在很短的时间内掌握该类别的特征，这一能力很可能来源于人脑中含有概念表征的组合结构（the compositional structure of concept representations），即人虽然没有见过该类别，但其能够迅速掌握该类别的一些高级特征（属性）。故此文尝试将图片的一些属性表征同时送入网络，增加信息量。</p><p><img src="/images/6.png" alt="Test"></p></li></ul><h5 id="算法特点："><a href="#算法特点：" class="headerlink" title="算法特点："></a>算法特点：</h5><ul><li><p>为了提高图像特征提取网络和属性特征提取网络的性能，在损失函数增加了一个软约束使得二者之间尽量相似</p><p><img src="/images/7.png" alt="Test"></p></li><li><p>为了降低各个属性表征之间的相关性，避免出现冗余属性，在损失函数中增加了正交约束</p></li></ul><h3 id="小样本开放集识别"><a href="#小样本开放集识别" class="headerlink" title="小样本开放集识别"></a>小样本开放集识别</h3><h4 id="Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition"><a href="#Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition" class="headerlink" title="Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition"></a>Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition</h4><h5 id="算法动机"><a href="#算法动机" class="headerlink" title="算法动机"></a>算法动机</h5><p>早先针对小样本开放集识别的方法，都是通过设定阈值区分正样本与负样本，该方法存在一些问题：</p><ul><li><p>首先，该阈值需要人工调整。</p></li><li><p>其次，不同的任务需要不同的阈值。</p></li><li><p>同一个任务，我们需要对每一个正样本都设定一个阈值，以便与负样本进行区分，设置起来非常麻烦</p><p>所以，文章将阈值调整嵌入模型中，让模型自己学习一个调整函数，根据不同的任务自适应的进行调整。</p><p><img src="/images/8.png" alt="Test"></p></li></ul><h5 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h5><ul><li><p>该算法设计了一个负样本原型以及阈值生成器，嵌入模型中，在模型的训练过程中进行学习，达到根据不同的任务，自适应阈值的效果。</p><p><img src="/images/9.png" alt="Test"></p></li></ul><h3 id="DN4算法复现"><a href="#DN4算法复现" class="headerlink" title="DN4算法复现"></a>DN4算法复现</h3><ul><li><h4 id="算法结构"><a href="#算法结构" class="headerlink" title="算法结构!"></a>算法结构!</h4><img src="/images/3.png" alt="Test"></li></ul><p>DN4是一种基于度量的小样本识别算法</p><p>1.首先是一个没有检测头，只有骨干网络的CNN，其作用就是提取图片中的特征，并以特征向量的形式表示</p><p>（hw，d），其中hw为特征图的大小，d为特征图的数量（通道数，深度）</p><p>2.接着是image-to-Class模块，该模块的作用就是将query image与support set中的images进行相似度度量，并确定其属于哪个类。具体来说，对于support set中的每一个类，我们对query image的每一个局部特征向量，都在support set中该类所有images的所有局部特征向量组成的集合中，使用k近邻算法找出余弦距离最近的k个特征向量，然后求和得到image-to-class（query image to support set中的一个类）的余弦距离总和，那么显然，该图片应该属于该距离最近的类，公式如下：</p><p><img src="/images/10.png" alt="Test"></p><ul><li><h4 id="代码实现（基于LibFewShot）"><a href="#代码实现（基于LibFewShot）" class="headerlink" title="代码实现（基于LibFewShot）"></a>代码实现（基于LibFewShot）</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image-to-Class模块</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        query_feat,</span></span><br><span class="line"><span class="params">        support_feat,</span></span><br><span class="line"><span class="params">        way_num,</span></span><br><span class="line"><span class="params">        shot_num,</span></span><br><span class="line"><span class="params">        query_num,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        t, wq, c, h, w = query_feat.size()</span><br><span class="line">        _, ws, _, _, _ = support_feat.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, c, hw -&gt; t, wq, hw, c -&gt; t, wq, 1, hw, c</span></span><br><span class="line">        query_feat = query_feat.view(t, way_num * query_num, c, h * w).permute(</span><br><span class="line">            <span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span></span><br><span class="line">        )</span><br><span class="line">        query_feat = F.normalize(query_feat, p=<span class="number">2</span>, dim=-<span class="number">1</span>).unsqueeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, ws, c, h, w -&gt; t, w, s, c, hw -&gt; t, 1, w, c, shw</span></span><br><span class="line">        support_feat = (</span><br><span class="line">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(t, way_num, c, shot_num * h * w)</span><br><span class="line">        )</span><br><span class="line">        support_feat = F.normalize(support_feat, p=<span class="number">2</span>, dim=<span class="number">2</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class="line">        <span class="comment"># 张量点乘，从算法上可以理解为只有4，5两个维度在做点乘，从功能上，结合上面的归一化操作</span></span><br><span class="line">        <span class="comment"># 这里实际上就是在计算query image和support image中局部特征向量之间的余弦相似度</span></span><br><span class="line">        relation = torch.matmul(query_feat, support_feat)</span><br><span class="line">        <span class="comment"># k近邻算法，只留下距离相近的k个值</span></span><br><span class="line">        topk_value, _ = torch.topk(relation, self.n_k, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 求余弦距离总和，代表image-to-class，即query image和supprot</span></span><br><span class="line">        score = torch.<span class="built_in">sum</span>(topk_value, dim=[<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure></div><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">support_feat = (</span><br><span class="line">            support_feat.view(t, way_num, shot_num, c, h * w)</span><br><span class="line">            .permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(t, way_num, shot_num * h * w, c)</span><br><span class="line">        )</span><br><span class="line">        support_feat = F.normalize(support_feat, p=<span class="number">2</span>, dim=<span class="number">2</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># t, wq, w, hw, shw -&gt; t, wq, w, hw, n_k -&gt; t, wq, w</span></span><br><span class="line">        <span class="comment"># relation = torch.matmul(query_feat, support_feat)</span></span><br><span class="line">        <span class="comment"># 改为欧式距离度量相似度，相应的support_feat张量的形状需改变一下</span></span><br><span class="line">        relation = torch.cdist(query_feat, support_feat, p=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></div></li><li><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><table><thead><tr><th>Shot</th><th>dn4-n</th><th>相似度衡量</th><th>特征图尺寸</th><th>测试集准确率</th></tr></thead><tbody><tr><td>1</td><td>3</td><td>余弦</td><td>$64<em>5</em>5$</td><td>30.345%</td></tr><tr><td>5</td><td>3</td><td>余弦</td><td>$64<em>5</em>5$</td><td>56.606%</td></tr><tr><td>5</td><td>5</td><td>余弦</td><td>$64<em>5</em>5$</td><td>55.148%</td></tr><tr><td>5</td><td>5</td><td>余弦</td><td>$32<em>5</em>5$</td><td>51.400%</td></tr><tr><td>5</td><td>5</td><td>欧式</td><td>$32<em>5</em>5$</td><td>22.380%</td></tr></tbody></table><p>时间与算力有限，没有做大规模的测试，只做了以上5组</p><p>可以发现，shot增加可以使准确率大幅上升，将相似度衡量方法换为欧式距离后准确率大幅下降</p><p>而dn4-n和特征图尺寸(主要是通道数/深度d)的变化对测试集影响不大</p></li></ul></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/%E7%A7%91%E7%A0%94/">#科研</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/2023/07/15/week3/"><span class="left arrow-icon flex-center"><i class="fa-solid fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">人生几何的科研之旅——第三周周报</span> <span class="post-nav-item">上一篇</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/2023/07/02/week1/"><span class="title flex-center"><span class="post-nav-title-item">人生几何的科研之旅——第一周周报</span> <span class="post-nav-item">下一篇</span> </span><span class="right arrow-icon flex-center"><i class="fa-solid fa-chevron-right"></i></span></a></div></div><div class="comment-container"><div class="comments-container"><div id="comment-anchor"></div><div class="comment-area-title"><i class="fa-solid fa-comments"></i>&nbsp;评论</div><div id="waline"></div><script type="module" data-pjax>import{init}from"https://evan.beee.top/js/waline.mjs";function loadWaline(){init({el:"#waline",serverURL:"blog-comment-mu-amber.vercel.app",lang:"zh-CN",dark:'body[class~="dark-mode"]',requiredMeta:["nick","mail"]})}{const e=setTimeout(()=>{loadWaline(),clearTimeout(e)},1e3)}</script></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><div class="toc-title">此页目录</div><div class="page-title">人生几何的科研之旅——第二周周报</div><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB"><span class="nav-text">多模态小样本图像识别</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Adaptive-Cross-Modal-Few-shot-Learning"><span class="nav-text">Adaptive Cross-Modal Few-shot Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8A%A8%E6%9C%BA%EF%BC%9A"><span class="nav-text">算法动机：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%EF%BC%9A"><span class="nav-text">算法原理：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Learning-Compositional-Representations-for-Few-Shot-Recognition"><span class="nav-text">Learning Compositional Representations for Few-Shot Recognition</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8A%A8%E6%9C%BA%EF%BC%9A-1"><span class="nav-text">算法动机：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E7%89%B9%E7%82%B9%EF%BC%9A"><span class="nav-text">算法特点：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%BC%80%E6%94%BE%E9%9B%86%E8%AF%86%E5%88%AB"><span class="nav-text">小样本开放集识别</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Task-Adaptive-Negative-Envision-for-Few-Shot-Open-Set-Recognition"><span class="nav-text">Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8A%A8%E6%9C%BA"><span class="nav-text">算法动机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="nav-text">算法原理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DN4%E7%AE%97%E6%B3%95%E5%A4%8D%E7%8E%B0"><span class="nav-text">DN4算法复现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%84"><span class="nav-text">算法结构!</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%88%E5%9F%BA%E4%BA%8ELibFewShot%EF%BC%89"><span class="nav-text">代码实现（基于LibFewShot）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-text">实验结果</span></a></li></ol></li></ol></div></div></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info">&copy; <span>2023</span> - 2023&nbsp;&nbsp;<i class="fa-regular fa-computer-classic"></i>&nbsp;&nbsp;<a href="/">人生几何</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item"><span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">访问人数&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span></span></div><div class="theme-info info-item"><span class="powered-by-container">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a> 驱动</span><br><span class="theme-version-container">主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v1.2.1</a></span></div><div id="start_time_div" style="display:none">2023/2/28 22:00:00</div><div>博客已运行 <span class="odometer" id="runtime_days"></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒</div><script async data-pjax>try{function odometer_init(){document.querySelectorAll(".odometer").forEach(e=>{new Odometer({el:e,format:"( ddd).dd",duration:200})})}odometer_init()}catch(e){}</script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="tools-list"><li class="right-bottom-tools page-aside-toggle"><i class="fa-regular fa-outdent"></i></li><li class="go-comment"><i class="fa-regular fa-comments"></i></li></ul></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="unfolded-tools-list"><li class="right-bottom-tools tool-font-adjust-plus flex-center"><i class="fa-regular fa-magnifying-glass-plus"></i></li><li class="right-bottom-tools tool-font-adjust-minus flex-center"><i class="fa-regular fa-magnifying-glass-minus"></i></li><li class="right-bottom-tools tool-expand-width flex-center"><i class="fa-regular fa-expand"></i></li><li class="right-bottom-tools tool-dark-light-toggle flex-center"><i class="fa-regular fa-moon"></i></li><li class="right-bottom-tools tool-scroll-to-top flex-center"><i class="fa-regular fa-arrow-up"></i></li><li class="right-bottom-tools tool-scroll-to-bottom flex-center"><i class="fa-regular fa-arrow-down"></i></li></ul><ul class="folded-tools-list"><li class="right-bottom-tools tool-toggle-show flex-center"><i class="fa-regular fa-cog fa-spin"></i></li></ul></div></div><div class="image-viewer-container"><img src=""></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fa-solid fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa-solid fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/utils.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/main.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/layouts/menu-shrink.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/go-top-bottom.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/dark-light-toggle.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/local-search.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/code-block.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/runtime.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/layouts/odometer.min.js"></script><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/assets/odometer-theme-minimal.css"><div class="post-scripts pjax"><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/tools/toc-toggle.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/libs/anime.min.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/layouts/toc.js"></script><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/plugins/tabs.js"></script></div><script src="//evan.beee.top/projects/hexo-theme-redefine/v1.2.1/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{REDEFINE.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{REDEFINE.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),REDEFINE.refresh()})})</script></body></html>